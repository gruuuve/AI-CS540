as
a
first
effort
in
a
series
of
investigations
,
artificial
intelligence
and
life
in
2030
offers
an
informative
overview
of
ai
and
encourages
further
discussion
regarding
the
role
of
ai
in
society
.
however
,
the
study
fails
to
recognize
a
significant
portion
of
the
us
population
and
its
arguments
for
transparency
and
minimal
regulation
are
underdeveloped
.
the
authors
limit
the
scope
of
the
report
to
``
typical
northern
american
cities
''
due
to
the
role
cities
have
played
in
human
history
.
at
the
same
time
,
the
authors
exhort
ai
professionals
and
policy
makers
to
``
avoid
discrimination
against
segments
of
society
.
''
by
ignoring
rural
populations
,
which
account
for
almost
20
%
of
the
us
and
canadian
population
,
the
study
itself
demonstrates
a
bias
towards
groups
with
greater
resources
.
by
only
considering
cities
,
the
existing
knowledge
and
digital
gap
between
urban
and
rural
zones
will
continue
to
widen
.
poverty
,
especially
deep
poverty
,
is
particularly
prevalent
in
rural
areas
and
is
growing
at
a
much
faster
rate
than
in
urban
regions
-lrb-
1
-rrb-
.
failing
to
consider
rural
populations
in
this
study
further
marginalizes
these
less
advantaged
groups
and
overlooks
an
opportunity
to
explore
ways
ai
can
potentially
benefit
these
communities
.
another
shortcoming
is
that
the
report
firmly
rejects
``
tougher
''
ai
regulation
based
on
current
us
privacy
policies
.
this
stance
is
supported
by
a
single
study
that
compares
us
and
eu
privacy
ecosystems
and
suggests
that
looser
regulations
in
the
us
have
led
to
more
innovation
and
greater
corporate
investment
in
privacy
.
yet
there
is
no
objective
evidence
demonstrating
privacy
is
actually
better
protected
in
the
us
.
it
could
even
be
argued
us
privacy
measures
are
inadequate
as
surveys
indicate
at
least
66
%
of
us
adults
have
no
confidence
that
online
service
providers
will
keep
their
records
private
and
secure
-lrb-
2
-rrb-
.
this
is
not
to
say
the
authors
are
wrong
in
advocating
a
flexible
legal
framework
for
ai
,
only
that
it
is
questionable
to
use
our
controversial
privacy
policies
as
a
model
without
acknowledging
its
weaknesses
.
lastly
,
the
report
calls
for
transparency
but
does
not
provide
a
definition
or
mention
the
ambiguities
inherent
in
this
recommendation
.
it
could
be
interpreted
as
calling
for
algorithmic
transparency
or
for
sharing
the
data
sets
used
to
train
models
.
even
with
this
information
,
we
do
not
truly
understand
the
workings
of
certain
algorithms
,
particularly
neural
networks
,
yet
these
are
precisely
the
kind
of
machine
learning
algorithms
that
offer
the
greatest
degree
of
accuracy
-lrb-
3
-rrb-
.
if
researchers
can
not
explain
the
exact
behavior
of
these
networks
,
then
does
this
report
suggest
we
compromise
these
better
performing
algorithms
for
less
accurate
,
but
more
interpretable
and
hence
,
more
transparent
ones
?
artificial
intelligence
and
life
in
2030
,
for
the
most
part
,
provides
multiple
perspectives
on
the
current
and
projected
state
of
ai
and
the
challenges
it
faces
.
nonetheless
,
there
are
some
shortcomings
in
the
choice
of
scope
and
in
the
presentation
of
the
guidelines
,
particularly
in
the
proposals
for
looser
regulation
and
greater
transparency
.
one
hopes
these
oversights
will
be
addressed
in
future
studies
,
as
doing
so
would
promote
a
more
inclusive
and
nuanced
conversation
of
this
complex
subject
.
-lrb-
1
-rrb-
t.
farrigan
,
``
poverty
and
deep
poverty
increasing
in
rural
america
,
''
(2014)
,
http://www.ers.usda.gov/amber-waves/2014-march/poverty-and-deep-poverty-increasing-in-rural-america.aspx
.
-lrb-
2
-rrb-
m.
madden
and
l.
rainie
,
``
americans
'
attitudes
about
privacy
,
security
and
surveillance
,
''
pew
research
center
(2015)
,
http://www.pewinternet.org/2015/05/20/americans-attitudes-about-privacy-security-and-surveillance/
.
-lrb-
3
-rrb-
a.
m.
bornstein
and
l.
m.
krauss
,
``
is
artificial
intelligence
permanently
inscrutable
?
,
''
nautilus
40
,
(2016)
,
http://nautil.us/issue/40/learning/is-artificial-intelligence-permanently-inscrutable
.
