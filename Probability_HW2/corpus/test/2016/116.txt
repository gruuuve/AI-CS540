artificial
intelligence
has
brought
a
lot
of
advancements
to
society
,
making
every
day
jobs
able
to
be
done
without
human
interaction
or
jobs
unable
to
be
done
by
human
interaction
,
possible
.
although
the
implementation
of
``
smart
cars
''
in
our
society
can
have
certain
benefits
,
there
are
limitations
to
how
far
artificial
intelligence
should
replace
human
intelligence
in
transportation
.
the
stanford
one
hundred
year
study
on
artificial
intelligence
poses
potential
befefits
such
as
decreased
vehicles
on
the
road
,
increased
life
expectancy
,
and
faster
commute
times
,
but
the
ideas
of
uncapped
benefit
ai
can
have
for
transportation
and
the
legal
repercussions
of
smart
cars
the
review
has
should
be
challenged
.
the
first
aspect
of
the
review
that
was
perplexing
to
me
came
with
the
use
of
the
fact
that
sensors
have
been
in
cars
since
before
2000
-lrb-
references
20-22
-rrb-
.
the
review
uses
this
fact
as
a
way
to
justify
that
sensors
should
be
used
as
much
as
possible
to
make
a
car
do
more
automated
things
.
i
would
challenge
this
by
saying
there
needs
to
be
a
line
drawn
to
how
much
artificial
intelligence
should
be
automating
our
driving
practices
.
the
line
should
be
made
to
only
allow
artificial
intelligence
to
modify
practices
of
an
active
human
driver
and
nothing
further
.
the
key
words
in
that
definition
are
modify
and
active
.
once
the
car
completely
takes
the
human
out
of
control
such
as
making
a
right
turn
by
itself
,
this
is
not
modifying
.
on
the
other
hand
,
if
a
sleepy
human
driver
starts
drifting
across
a
line
and
the
car
detects
this
and
diverts
the
car
to
stay
in
the
lane
,
that
is
a
small
modification
necassary
for
the
safety
of
the
driver
and
the
other
people
in
the
car
.
the
second
key
word
is
alert
,
simply
meaning
the
driver
should
not
be
able
to
take
a
nap
or
do
another
activity
while
the
artificial
intelligence
takes
over
.
although
the
review
states
that
self-driving
cars
have
humans
``
expected
to
stay
engaged
and
take
over
if
they
detect
a
potential
problem
''
,
in
reality
this
would
not
happen
.
a
related
aspect
of
the
review
that
i
want
to
challenge
is
first
part
of
the
question
:
``
who
is
responsible
when
a
self-driven
car
crashes
or
an
intelligent
medical
device
fails
?
''
.
i
do
give
credit
for
the
review
for
addressing
this
situation
,
but
i
felt
the
response
underaddressed
the
situation
.
a
preceeding
question
is
who
is
considered
the
driver
in
a
self-driving
system
?
a
short
answer
was
given
by
the
nhtsa
that
the
system
rather
than
the
occupant
is
considered
the
driver
while
driving
.
what
is
not
addressed
is
what
happens
in
the
situation
of
transitioning
between
the
system
and
the
occupant
driving
?
or
what
happens
when
a
crash
is
imminent
while
self-driving
,
but
the
the
human
tries
to
take
over
at
the
last
second
and
makes
a
bad
mistake
that
the
system
would
n't
have
made
?
the
only
answer
to
these
questions
will
be
found
when
the
situation
actually
happens
and
the
driver
-lrb-
assuming
the
accident
is
n't
fatal
-rrb-
goes
to
court
against
the
car
company
or
the
ai
delevoper
,
by
which
time
it
is
too
late
.
