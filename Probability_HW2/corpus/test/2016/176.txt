``
artificial
intelligence
and
life
in
2030
''
covers
various
topics
,
including
current
progress
and
predictions
of
future
innovations
across
numerous
domains
,
although
there
are
points
of
debate
.
specifically
,
it
paints
an
overly
optimistic
picture
of
how
ai
will
benefit
society
by
measuring
the
success
of
ai
as
how
much
value
it
adds
to
human
lives
and
encouraging
trust
in
these
applications
,
although
there
are
reasons
to
be
cautious
.
pages
10
and
42
state
``
the
measure
of
success
for
ai
applications
is
the
value
they
create
for
human
lives
''
-lrb-
stone
,
2016
-rrb-
.
however
,
applications
benefiting
other
living
organisms
or
the
environment
should
also
be
considered
valuable
.
as
ai
develops
,
many
jobs
will
be
replaced
by
products
of
ai
.
many
find
value
in
their
work
to
enriching
their
lives
and
contribute
to
society
.
although
the
report
mentions
how
automation
could
lower
costs
of
goods
and
services
,
if
those
displaced
of
work
can
not
find
new
jobs
or
there
does
not
exist
political
changes
to
rectify
this
,
the
economic
and
societal
effects
could
be
profound
.
on
a
philosophical
level
,
humans
have
long
been
considered
the
most
intelligent
species
.
what
happens
if
or
when
ai
exceeds
human
intelligence
?
what
is
the
value
of
humans
if
everything
can
be
done
by
machine
?
thus
,
ai
's
success
can
not
be
fully
measured
by
the
value
it
creates
for
human
lives
;
there
will
be
various
negative
and
unforeseen
consequences
.
again
,
pages
10
and
42
express
how
ai
applications
should
be
designed
to
build
people
's
trust
.
though
the
benefits
of
ai
applications
are
numerous
,
various
reasons
and
events
indicate
trust
should
be
limited
.
creating
perfect
software
is
arguably
impossible
;
bugs
are
prevalent
in
any
piece
of
extensive
software
.
special
care
is
necessary
to
ensure
applications
work
correctly
as
intended
and
avoid
harmful
or
offending
results
,
especially
if
there
are
issues
in
data
.
for
example
,
google
's
photos
application
mislabelled
african
americans
as
gorillas
-lrb-
dougherty
,
2015
-rrb-
.
furthermore
,
microsoft
's
twitter
bot
tay
produced
many
racist
,
sexist
,
and
otherwise
obscene
tweets
less
than
24
hours
after
its
release
-lrb-
victor
,
2016
-rrb-
.
some
may
intentionally
fool
around
with
ai
applications
,
producing
undesired
results
if
there
lacks
proper
precaution
.
more
physically
dangerous
incidents
could
occur
,
and
efforts
should
be
made
to
consider
how
to
prevent
ai
applications
from
being
used
in
harmful
ways
.
recently
,
it
was
revealed
how
an
autonomous
car
's
sensors
could
be
hacked
with
a
simple
setup
.
karl
iagnemma
,
director
of
the
robotic
mobility
group
at
mit
,
stated
``
the
biggest
threat
to
an
occupant
of
a
self-driving
car
today
is
n't
any
hack
,
it
's
the
bug
in
someone
's
software
because
we
do
n't
have
systems
that
we
're
100-percent
sure
are
safe
''
-lrb-
harris
,
2015
-rrb-
.
while
it
's
not
to
say
there
will
never
be
trustworthy
applications
,
it
's
crucial
to
be
cautious
and
realize
various
factors
may
affect
the
safety
of
an
application
or
produce
unintended
results
.
though
the
report
provides
much
insight
into
current
applications
of
ai
in
various
fields
and
predictions
for
the
future
,
there
remain
points
of
contention
.
namely
,
the
report
's
view
of
how
ai
will
benefit
society
is
overly
idealistic
and
should
reconsider
how
to
gauge
the
success
of
ai
applications
,
including
their
potentially
negative
effects
,
along
with
being
more
critical
of
how
much
trust
to
place
in
these
applications
.
references
stone
,
p.
artificial
intelligence
and
life
in
2030
.
stanford
university
,
2016
.
victor
,
d.
microsoft
created
a
twitter
bot
to
learn
from
users
.
it
quickly
became
a
racist
jerk
.
the
new
york
times
,
2016
.
dougherty
,
c.
google
photos
mistakenly
labels
black
people
`
gorillas
'
.
the
new
york
times
,
2015
.
