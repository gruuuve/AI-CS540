the
stanford
hundred
year
study
report
asserts
that
there
is
no
cause
for
concern
that
artificial
intelligence
is
an
imminent
threat
to
humankind
but
the
report
does
n't
clearly
address
or
cover
the
human
security
implications
of
ai
or
neither
address
the
long-term
concerns
or
risk
associated
with
it
in
detail
.
the
stanford
hundred
year
study
report
envision
the
use
and
implications
of
artificial
intelligence
in
day
to
day
life
over
a
hundred
year
span
and
mentions
the
several
key
areas
where
ai
will
have
a
significant
impact
-lrb-
for
ex
.
eight
domains
-
transportation
,
education
,
healthcare
,
etc.
-rrb-
and
identifies
the
promising
areas
of
research
in
ai
.
ai
has
been
prominent
in
our
lives
for
over
a
decade
now
in
various
forms
and
we
have
been
depending
on
it
unknowingly
for
ex
.
smartphones
equipped
with
speech
recognition
tries
to
understand
and
talk
to
the
user
,
gps
helps
us
finding
an
optimal
route
,
google
photos
identifying
individual
faces
,
youtube
,
and
other
search
engines
recommendation
,
self-driving
cars
,
robots
in
healthcare
and
others
in
the
field
of
science
,
etc.
.
as
we
can
see
,
ai
has
reached
out
to
millions
of
users
and
has
been
helping
predict
things
and
making
life
easier
.
this
raises
a
concern
that
machine
can
outsmart
human
intelligence
to
some
extent
and
can
be
a
threat
to
humanity
if
not
used
under
supervision
or
not
having
the
human
in
the
loop
.
the
equation
of
removing
human\/supervision
from
the
loop
can
have
serious
security
threats
if
certain
sensitive
data
or
program\/devices
-lrb-
for
example
,
the
location
of
army
bases\/security
agents
in
a
different
country
-rrb-
are
made
available
to
an
autonomous
computer
system
which
can
communicate
to
other
systems
in
the
loop
.
the
stanford
report
mentions
that
special
purpose
robots
will
deliver
packages
,
clean
offices
and
will
enhance
security
-
the
reliance
on
machine\/system
without
supervision
for
control
raises
potential
risks
and
can
be
dangerous
if
gone
wrong
.
the
report
also
mentions
that
north
american
cities
and
federal
agencies
have
already
begun
to
use\/deploy
ai
technologies
in
border
administration
and
law
enforcement
and
by
2030
,
they
will
be
heavily
relying
on
ai
.
i
believe
that
this
is
a
good
start
but
the
ai
study
should
also
include
concerns
of
innocent
people
who
are
being
unnecessarily
monitored
and
severe
tests
should
be
done
to
make
sure
that
their
information
is
not
leaked
to
dangerous
people
or
malicious
bots\/systems
.
i
agree
with
the
statement
in
the
report
that
further
research
on
fairness
,
security
,
privacy
and
societal
implications
of
ai
systems
should
be
encouraged
not
by
removing
the
impediments
but
by
addressing
the
concerns
,
risks
and
security
and
thoroughly
testing\/supervising
the
system
and
increasing
private
and
public
spending
to
support
it
.
computer
society
should
continue
researching
and
addressing
concerns
about
the
possibilities
of
machine
intelligence
failure\/takeover
and
address
risks
associated
with
autonomous\/semi-autonomous
computer
systems
that
are
involved
in
decision-making
tasks
.
another
set
of
problem
that
should
be
addressed
is
the
risk
of
cyber
attacks
where
bots
,
criminals
,
and
malicious
software
attack
computers
to
gain
control
and
access
sensitive
information
.
the
evolution
of
ai
algorithms
and
machines
also
possess
the
same
threat
,
for
ex
.
a
malware
can
hamper
the
training
data
and
can
cause
the
system
to
behave
differently
.
