self-driving
vehicles
?
too
good
to
be
true
the
future
picture
of
the
self-driving
vehicles
in
this
report
might
be
over
optimistic
.
when
it
comes
to
the
life
of
human
,
the
requirement
to
the
ai
should
never
be
just
reliable
enough
,
but
be
completely
flawless
.
to
achieve
this
goal
,
we
are
to
polish
the
software
which
we
know
is
unfortunately
error
prone
.
we
do
tests
and
debugging
,
but
how
?
simulation
is
not
sufficient
,
we
have
to
do
tests
on
a
real
road
,
in
a
real
complex
traffic
,
with
real
human
getting
involved
.
but
the
bugs
here
are
no
joke
,
it
's
not
like
when
you
run
a
program
on
the
computer
and
an
error
message
pop
out
and
you
can
always
reboot
the
machine
,
it
might
be
severe
car
crash
and
people
may
die
.
the
cost
of
doing
tests
is
too
expensive
to
afford
.
yes
,
ai
application
in
healthcare
robotics
should
also
be
extremely
serious
on
human
life
,
but
that
is
a
different
case
.
there
may
be
volunteers
who
would
generously
donate
their
body
after
death
for
experiment
and
research
use
.
there
may
be
pioneers
who
bravely
would
like
to
try
the
new
technology
at
their
own
risk
.
the
most
important
thing
is
,
only
themselves
are
involved
.
should
any
accident
happen
,
no
one
else
would
get
hurt
.
here
comes
the
difference
.
once
a
self-driving
car
was
allowed
on
the
way
,
it
does
not
only
take
the
risk
of
the
lives
of
the
passengers
on
this
car
,
but
also
put
everyone
else
who
happen
to
be
on
the
same
road
at
that
time
in
danger
.
before
the
ai
being
perfect
,
it
is
not
acceptable
.
however
,
in
the
pursuit
of
perfection
,
we
have
to
do
lots
of
tests
which
means
self-driving
cars
have
to
be
on
the
road
.
it
's
kind
of
a
dead
loop
.
besides
,
ai
is
not
human
after
all
.
problems
occur
when
it
needs
to
interact
with
human
.
when
we
are
driving
a
car
,
we
use
eye
contacts
and
gestures
to
communicate
with
other
vehicles
,
cyclists
,
and
pedestrians
.
how
do
an
ai
read
a
man
's
face
and
determine
whether
he
would
like
to
go
or
stop
?
what
if
this
guy
suddenly
change
his
mind
?
even
if
this
problem
could
ever
be
solved
with
some
super
fancy
technologies
in
the
future
,
ai
is
still
not
able
to
make
choices
as
human
do
.
for
example
,
as
mentioned
in
this
report
,
in
situations
in
which
human
injury
or
death
is
inevitable
,
you
'll
have
make
a
choice
about
whom
to
put
at
risk
.
an
ai
maybe
does
a
series
of
complicated
computation
on
thousands
of
input
and
get
to
one
decision
,
however
,
we
human
do
n't
do
that
rationally
,
it
's
mostly
about
instinct
.
instinct
will
never
be
found
on
even
the
most
advanced
ai
.
ai
is
not
human
after
all
.
