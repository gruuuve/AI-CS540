the
report
provides
a
comprehensive
and
clear
outline
of
ai
s
applications
on
daily
life
.
i
am
greatly
impressed
by
two
points
,
one
is
the
predicted
wide
application
of
self-driving
vehicles
in
2020
,
the
other
is
that
the
machine
will
be
able
to
make
human-like
dialogue-based
interactions
.
in
this
article
,
i
want
to
make
some
arguments
based
on
these
two
points
.
although
they
are
both
theoretically
feasible
,
there
are
still
limitations
of
current
algorithms
,
and
these
limitations
are
evident
as
shown
in
experiments
.
firstly
,
self-driving
vehicles
are
unlikely
to
be
widely
adopted
in
2020
.
based
on
results
in
latest
research
papers
,
accuracy
of
ai
and
ml
algorithms
to
predict
locations
given
the
test
dataset
still
need
further
improvement
.
although
datasets
containing
long
image
sequences
in
various
conditions
are
available
,
the
model
trained
by
them
is
still
not
sufficiently
accurate
as
shown
by
prediction
on
test
datasets
.
it
is
because
of
the
limitation
of
depth
computation
-lrb-
extraction
of
important
features
from
given
images
-rrb-
,
which
is
significant
to
predict
poses
-lrb-
transition
and
rotation
between
two
neighbor
frames
-rrb-
.
algorithms
to
resolve
the
challenge
of
depth
computation
keep
advancing
for
ten
years
.
but
there
are
still
significant
difference
between
the
result
of
the
model
and
the
ground
truth
.
depth
prediction
of
dense
and
semi-dense
images
are
much
more
challenging
.
the
error
of
the
depth
prediction
will
propagate
into
the
prediction
of
poses
,
which
makes
the
model
unable
to
reach
the
standard
to
be
widely
applied
.
error
of
imu
sensor
and
the
camera
parameters
are
also
drawbacks
that
hinder
wide
applications
.
since
the
transformation
and
projection
matrix
are
computed
from
the
parameters
of
camera
and
sensors
,
the
computed
matrix
are
not
accurate
so
that
the
predicted
result
computed
by
multiplying
matrixes
is
usually
not
reliable
.
but
the
good
news
is
that
ar
technology
manages
to
conduct
plane
detection
,
trajectory
depiction
,
and
distance
measurement
.
people
can
have
amazing
experience
with
arcore
and
arkit
.
arcore
and
arkit
are
able
to
accurately
track
the
location
of
the
device
and
make
adjustments
on
analyzed
results
based
on
the
environment
the
device
senses
.
the
algorithms
estimate
the
texture
of
object
appearing
on
images
based
on
optical
flows
and
data
of
sensors
.
some
researches
aim
to
apply
the
algorithms
on
pose
estimation
during
longer
periods
.
but
the
results
are
different
since
the
error
can
easily
accumulate
during
the
process
.
thus
,
it
is
not
realistic
to
apply
them
to
self-driving
vehicles
.
another
point
i
want
to
argue
is
that
the
limitations
of
nlp
algorithms
are
underestimated
in
the
report
.
undoubtedly
,
google
translate
is
a
huge
success
and
there
are
few
bugs
when
using
it
.
but
it
is
not
realistic
to
expect
rapid
development
of
the
human-like
generator
.
either
microsoft
tag
developed
in
2017
or
daodao
accounting
app
developed
in
2019
,
a
famous
app
in
china
is
only
able
to
react
with
very
simple
and
rudimentary
sentences
.
although
there
are
huge
progress
in
the
domain
of
semantic
understanding
and
sentence
parsing
,
which
helps
resolve
challenges
for
machine
to
understand
natural
language
correctly
,
chatting
with
human
is
a
different
thing
.
because
there
are
no
fixed
labels
for
training
and
the
input
features
to
the
training
network
grow
increasingly
complicated
when
the
dialogue
gets
longer
.
although
microsoft
tag
play
easy
games
and
answer
some
questions
of
the
users
,
they
can
not
perform
certainly
well
in
all
user
cases
.
