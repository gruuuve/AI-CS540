artificial
intelligence
-lrb-
ai
-rrb-
has
occurred
in
the
field
of
healthcare
and
clinical
decision
support
for
some
time
and
has
an
increasing
trend
to
be
employed
in
the
area
-lrb-
1
-rrb-
.
further
,
the
article
ai100
suggests
that
the
necessary
condition
for
ai-based
applications
to
improve
people
'
s
health
outcome
is
that
medical
practitioners
and
patients
must
trust
the
ai
and
that
policies
do
not
impede
the
employment
of
these
techniques
-lrb-
2
-rrb-
.
however
,
these
are
far
from
enough
.
additionally
,
these
ai
applications
themselves
should
be
reliable
,
and
we
know
how
they
function
should
also
be
included
in
these
critical
conditions
.
ai
is
somehow
a
black-box
,
which
may
go
wrong
without
our
awareness
.
nowadays
,
most
state-of-art
algorithms
and
models
are
very
complex
and
end
to
end
,
like
xgboost
and
deep
neural
networks
.
it
is
hard
for
us
to
track
what
happened
inside
the
model
.
the
case
is
that
we
give
inputs
and
get
outputs
,
but
we
do
not
know
why
we
get
this
output
,
what
makes
the
model
give
this
prediction
,
and
what
is
the
most
significant
feature
in
the
inputs
.
one
of
the
most
severe
consequences
may
be
that
we
may
not
know
whether
the
result
is
correct
or
not
,
or
in
other
words
,
we
have
no
idea
when
the
model
will
go
wrong
.
the
black-box
model
is
a
severer
problem
in
the
field
of
health
care
and
clinical
decision
support
.
although
the
ai
medical
applications
can
achieve
extraordinary
accuracy
,
are
easier
to
train
compared
with
an
experienced
doctor
,
and
are
much
more
convenient
,
the
risks
of
making
vital
mistakes
are
still
there
.
many
results
also
show
that
some
deep
learning
models
are
not
robust
.
a
small
perturbation
in
the
input
images
will
lead
to
a
giant
gap
in
the
outputs
.
besides
,
it
is
also
possible
that
the
results
of
ai
may
mislead
the
doctors
due
to
a
lack
of
knowledge
concerning
the
interior
of
the
black-box
model
.
hence
,
it
is
not
enough
that
ai
applications
can
convince
people
.
they
must
be
trustworthy
,
and
we
should
at
least
have
some
methods
to
verify
whether
these
models
are
working
correctly
and
alert
when
they
go
wrong
.
the
algorithm
and
model
only
give
accurate
predictions
,
but
not
causes
and
reasons
-lrb-
3
-rrb-
.
most
of
the
state-of-art
models
are
trained
to
minimize
the
loss
functions
.
therefore
models
perform
certain
computations
simply
because
doing
in
this
way
will
result
in
the
least
loss
values
instead
of
learning
some
``
knowledge
''
from
the
data
given
.
a
simple
example
is
that
a
well-trained
doctor
on
ct
images
does
not
perform
considerably
differently
when
given
mr
images
of
the
same
organ
,
but
a
deep
neural
network
does
since
ct
and
mr
images
have
different
domains
.
it
means
that
the
dnn
did
not
learn
the
structural
information
or
the
abstract
features
from
the
ct
images
,
but
human
does
.
although
much
research
is
targeting
the
problem
,
the
phenomena
reveal
that
a
well-trained
deep
neural
network
may
not
acquire
the
``
knowledge
''
we
expect
it
to
acquire
.
hence
,
before
we
massively
put
ai
applications
in
practice
,
we
need
to
make
sure
they
are
reliable
and
make
the
black
box
whiter
.
all
in
all
,
there
is
still
a
long
way
to
go
for
ai
applications
,
from
convincing
people
to
being
reliable
.
we
also
have
much
work
to
do
to
make
the
black
box
model
explainable
.
reference
:
-lrb-
1
-rrb-
davenport
,
t.
,
&
kalakota
,
r.
(2019)
.
the
potential
for
artificial
intelligence
in
healthcare
.
future
healthcare
journal
,
6
(2)
,
94
.
-lrb-
2
-rrb-
stone
,
p.
,
brooks
,
r.
,
brynjolfsson
,
e.
,
calo
,
r.
,
etzioni
,
o.
,
hager
,
g.
,
...
&
leyton-brown
,
k.
(2016)
.
artificial
intelligence
and
life
in
2030
.
one
hundred
year
study
on
artificial
intelligence
:
report
of
the
2015-2016
study
panel
,
52
.
