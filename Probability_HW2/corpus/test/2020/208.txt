the
us
faces
a
dramatic
rate
of
over-policing
and
police
brutality
especially
among
people
of
color
.
this
is
due
to
human
bias
,
more
specifically
racial
bias
.
implementation
of
robust
artificial
intelligence
systems
to
supplement
public
safety
and
security
in
metropolitan
areas
will
not
have
a
positive
effect
on
public
safety
nor
will
it
gain
the
trust
of
the
residents
of
low-resource
communities
living
in
densely
populated
cities
where
artificial
intelligence
would
be
a
candidate
for
implementation
.
initial
implementation
of
ai
would
rely
on
data
being
fed
through
a
neural
net
,
but
no
unbiased
data
has
been
collected
from
communities
of
color
or
other
low-resource
communities
.
the
only
data
available
for
ai
use
of
these
communities
are
from
the
police
agencies
,
where
data
collected
of
offenders
and
other
detained
persons
are
disproportionately
people
of
color
moreover
:
black
men
.
many
of
these
communities
have
also
been
flagged
by
police
as
volatile
or
high
crime
areas
possibly
making
these
communities
a
focus
when
ai
would
be
used
to
predict
crime
.
this
would
lead
to
a
continued
,
disproportionate
rate
of
arrest
of
these
communities
.
the
article
mentions
cameras
being
used
for
surveillance
and
prevention
of
crimes
using
mass
analysis
of
video
streams
of
events
occurring
in
real
time
.
this
approach
seems
to
have
both
positive
and
negative
implications
.
positive
outcomes
include
a
swift
response
from
law
enforcement
when
a
crime
in
occurring
as
well
as
accountability
for
the
police
in
a
time
when
many
communities
distrust
police
.
negative
results
from
surveillance
streams
are
privacy
issues
mentioned
in
the
paper
,
as
well
as
possible
over-policing
of
low-resource
communities
.
with
respect
to
social
media
and
national
security
,
i
believe
that
strong
use
of
artificial
intelligence
will
also
be
backed
with
a
heavy-handed
use
of
bias
.
the
use
of
ai
in
social
media
platforms
to
comb
through
posts
to
see
if
there
are
any
terrorist
sentiment
seems
useful
,
but
what
would
constitute
terrorist
sentiment
,
and
would
criticism
of
the
state
be
considered
terrorist
sentiment
?
national
security
agencies
such
as
tsa
has
always
operated
with
bias
,
with
respect
to
random
searches
usually
of
persons
of
possible
middle
eastern
heritage
.
reading
how
this
agency
plans
on
relying
more
on
ai
to
streamline
their
operations
makes
me
believe
that
this
tool
could
also
be
used
in
the
same
xenophobic
way
,
by
continuing
to
target
persons
of
middle
eastern
descent
.
i
believe
that
artificial
intelligence
can
offer
humanity
new
avenues
for
innovation
and
solutions
toward
large
scale
problems
such
as
global
climate
change
.
for
a
long
time
into
the
future
artificial
intelligence
will
be
used
as
a
tool
and
not
as
an
autonomous
entity
operating
for
humanity
.
this
means
ai
is
subject
to
bias
by
humans
operating
this
tool
,
contrary
to
the
possible
claims
in
reduction
in
bias
.
people
in
power
tend
to
submit
to
bias
,
whether
implicit
or
explicit
,
and
has
a
wide
scale
impact
on
their
constituents
.
if
ai
is
to
play
a
major
role
in
our
livelihoods
and
safety
,
transparency
is
owed
to
the
communities
being
subject
to
ai
monitors
.
