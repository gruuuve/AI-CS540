the
ai100
report
of
the
2015
study
panel
encompasses
a
wide
variety
of
themes
regarding
artificial
intelligence
and
life
in
2030
,
as
it
relates
to
a
typical
north
american
city
.
one
of
the
themes
,
interwoven
through
the
domains
,
was
regulation
of
ai
in
each
individual
sector
.
the
terminology
they
use
regarding
the
food
and
drug
administration
-lrb-
fda
-rrb-
,
aggressive
regulation
,
is
an
apt
depiction
of
how
they
attempt
to
frame
the
discussion
around
regulation
.
i
disagree
with
the
ai100
report
regarding
the
effects
of
regulation
in
various
sectors
,
and
the
feasibility
or
applicability
of
regulations
across
sectors
.
regulation
in
the
private
sector
is
often
described
as
a
necessary
evil
for
the
purposes
of
encouraging
development
of
existing
and
novel
technologies
,
while
also
balancing
against
the
excesses
of
corporate
greed
and
encapsulation
of
a
given
market
.
the
unique
nature
of
artificial
intelligence
,
in
the
sense
that
proper
and
novel
usage
of
ai
to
reconsolidate
and
efficiently
interacting\/disrupting
markets
to
glean
novel
insights
,
can
generate
significant
fiscal
profits
for
an
existing
company
.
as
such
,
care
should
be
taken
that
specific
human
rights
to
privacy
and
to
our
own
information
are
not
used
in
such
a
way
to
provide
a
net-negative
to
the
average
individual
.
from
transportation
services
to
pipelines
of
food
to
specific
consumer
markets
,
the
requisite
information
and
effects
cover
such
a
wide
swath
of
subjects
that
to
apply
broad
regulations
is
a
weak
approach
,
and
regulating
via
sectors
self-informed
by
ai
specialists
with
a
focus
on
generating
growth
for
humanity
as
a
whole
is
the
kind
of
approach
that
should
be
emphasized
.
the
ai100
report
,
as
a
whole
,
is
very
positively-framed
towards
the
benefits
of
ai
,
and
elements
such
as
the
impact
on
low-resource
communities
are
often
framed
in
a
positive
way
,
ignoring
the
practical
aspects
describing
which
communities
will
harvest
the
majority
of
the
wealth
generated
.
another
element
discussed
is
the
usage
of
machine
learning
for
predictive
policing
,
and
they
offer
the
new
york
police
department
's
compstat
as
a
tool
being
used
for
predictive
policing
.
while
they
do
discuss
the
issues
involved
in
generating
and
training
these
models
,
they
gloss
over
the
regulations
that
would
help
protect
the
average
or
low-resource
citizen
from
bias
inherent
to
the
data
used
to
train
such
systems
.
for
instance
,
while
this
paper
was
published
in
2016
,
and
the
discussion
occurred
in
2015
,
in
2014
there
was
an
expose
by
eterno
,
verma
,
and
silverman
et
.
al
that
discussed
the
police
manipulation
of
compstat
and
the
``
corruption
pressures
''
that
``
distort
and
corrupt
the
social
pressures
it
is
intended
to
monitor
.
''
.
whistleblowers
have
even
provided
audiotapes
indicating
that
the
crime
reports
,
which
serve
as
the
bulk
of
the
data
used
to
train
such
models
for
predictive
policing
,
have
undergone
significant
tampering
to
meet
metrics
and
avoid
transparency
.
regulation
regarding
the
usage
of
ai
in
such
spheres
is
a
necessity
in
this
world
.
in
brief
,
the
ai100
report
was
a
very
comprehensive
summary
of
the
discussion
that
occurred
in
2015
but
suffers
from
negative
phrasing
and
the
pointed
absence
of
comments
discussing
the
benefits
of
regulation
in
private
sectors
.
hopefully
,
in
the
ai100
report
to
be
released
in
2021
,
they
focus
less
on
the
holistic
positive
elements
and
truly
assess
the
impact
of
artificial
learning
on
the
previous
years
with
a
critical
eye
.
