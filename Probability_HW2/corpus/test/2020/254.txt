there
is
certainly
no
question
whether
the
introduction
of
artificial
intelligence
would
affect
our
society
as
a
whole
or
not
.
however
,
whether
or
not
that
introduction
will
provide
benefits
instead
of
costs
is
still
an
unanswered
question
.
stanford
's
2016
report
on
the
one
hundred
year
study
on
artificial
intelligence
provides
a
positive
tone
on
artificial
intelligence
in
2030
--
but
are
their
arguments
justified
?
what
about
other
negative
effects
that
it
might
cause
?
one
point
that
the
report
touched
on
was
in
regard
to
transportation
--
how
artificial
intelligence
will
provide
self-driving
cars
and
reduce
the
number
of
accidents
,
increasing
the
life
expectancy
of
the
general
public
.
this
idea
,
however
,
hides
the
fact
that
artificial
intelligence
can
still
make
mistakes
-lrb-
although
obviously
a
lot
less
compared
to
human
drivers
-rrb-
.
now
,
this
raises
serious
ethical
and
legal
questions
.
if
a
self-driving
car
had
to
choose
between
saving
the
life
of
its
passengers
or
the
life
of
pedestrians
,
who
should
it
choose
?
do
we
need
to
take
account
of
their
ages
?
should
it
prioritize
children
or
seniors
?
does
the
quantity
of
lives
being
saved
matter
?
these
questions
need
to
be
answered
before
self-driving
cars
become
mainstream
.
furthermore
,
if
a
self-driving
car
would
get
into
an
accident
,
what
would
the
insurance
policy
be
like
?
who
should
be
held
accountable
?
should
the
companies
who
made
the
car
or
developed
the
artificial
intelligence
be
held
accountable
or
should
the
owners
of
the
car
be
held
accountable
?
it
is
not
a
matter
of
if
a
self-driving
car
gets
into
an
accident
,
but
when
it
does
.
another
point
the
report
stated
was
that
artificial
intelligence
will
increase
public
safety
and
security
.
by
implementing
predictive
ai
into
surveillance
cameras
and
social
media
,
we
can
anticipate
crime
and
create
a
safer
society
.
this
,
however
,
also
raises
some
ethical
questions
about
privacy
.
should
a
predictive
ai
be
fed
millions
of
user
data
without
their
consent
?
even
if
we
ask
for
consent
,
would
the
user
even
give
consent
if
they
knew
that
the
data
will
be
used
to
surveil
on
them
?
what
about
bias
?
there
are
numerous
examples
already
today
regarding
ai
or
algorithmic
systems
implemented
to
predict
the
probability
of
a
person
to
commit
a
crime
being
biased
towards
african
american
people
.
the
compas
-lrb-
correctional
offender
management
profiling
for
alternative
sanctions
-rrb-
software
was
developed
to
predict
the
risk
of
a
defendant
in
a
trial
to
becoming
a
recidivist
.
in
some
parts
of
the
country
,
this
software
has
been
used
to
predict
and
supposedly
gave
a
harsher
sentence
to
the
defendant
-lrb-
loomis
v.
wisconsin
-rrb-
.
