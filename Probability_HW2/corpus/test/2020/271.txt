after
reading
the
article
artificial
intelligence
and
life
in
2030
-lrb-
stone
et
al.
,
2016
-rrb-
,
i
have
learned
a
lot
about
the
development
tendency
of
artificial
intelligence
-lrb-
ai
-rrb-
and
the
prospects
of
the
life
with
advanced
ai
for
the
next
few
decades
.
the
points
raised
in
the
nominated
article
are
considerably
insightful
and
constructive
,
whereas
i
will
challenge
the
part
of
viewpoints
about
public
safety
and
security
with
developed
ai
in
2030
in
this
essay
.
the
nominated
article
briefly
depicts
that
ai
will
be
more
involved
in
public
safety
and
security
.
ai
technology
will
be
widely
used
in
smart
cameras
,
drones
,
and
software
to
dominate
social
security
maintenance
,
criminal
model
analysis
,
and
prevention
of
criminality
.
the
application
of
ai
technology
will
effectively
reduce
or
even
remove
the
subjective
bias
of
human
judgment
.
simultaneously
,
public
safety
and
security
will
be
enhanced
without
violating
individual
freedoms
and
dignity
-lrb-
stone
et
al.
,
2016
-rrb-
.
the
prospect
delineated
in
the
article
seems
quite
appealing
where
the
ai
technology
would
play
a
dominant
and
powerful
role
in
protecting
and
maintaining
the
safety
and
security
of
the
public
and
community
.
nevertheless
,
there
is
a
fatal
factor
still
existing
confronting
the
comprehensive
application
of
ai
technology
in
the
fields
of
monitoring
,
assessing
and
reacting
security
incidents
and
infringement
,
which
the
adversarial
attacks
against
the
ai
technologies
in
terms
of
the
neural
network
,
machine
learning
,
and
deep
learning
.
in
recent
years
,
adversarial
sample
attacks
have
become
a
research
hotspot
.
with
the
extensive
research
and
application
of
deep
learning
,
the
security
threats
of
adversarial
attacks
to
deep
learning
have
become
more
serious
.
a
paper
-lrb-
thys
,
van
ranst
and
goedem
,
2019
-rrb-
published
on
the
cvpr
,
i.e.
artificial
intelligence
top
conference
,
stated
that
adversarial
attacks
can
make
a
person
almost
invisible
in
front
of
the
camera
.
it
was
found
that
it
could
cause
the
machine
to
make
a
wrong
judgment
of
human
identity
after
the
sample
interference
is
deployed
to
counter
the
face
recognition
algorithm
,
which
could
cause
the
ai-enhanced
cameras
to
fail
to
identify
criminals
or
suspects
-lrb-
kurakin
,
goodfellow
and
bengio
,
2018
-rrb-
.
currently
,
adversarial
sample
attacks
are
concentrated
in
the
field
of
image
recognition
,
and
enormous
adversarial
sample
algorithms
have
been
proposed
and
applied
.
in
the
images
generated
by
most
attack
algorithms
,
due
to
the
small
degree
of
processing
of
the
image
,
humans
can
hardly
distinguish
whether
they
have
been
processed
,
whereas
the
machine
will
be
deceived
by
this
.
to
make
matters
worse
,
the
attack
algorithm
has
strong
migration
.
the
attacking
algorithms
that
are
effective
against
certain
network
structures
generally
have
certain
deceptive
effects
against
other
network
structures
.
in
the
future
,
with
the
continuous
development
of
ai
technology
,
the
security
threats
generated
by
adversarial
attacks
will
also
gradually
emerge
and
become
more
serious
.
future
attackers
may
even
use
optimized
ai
technology
to
automatically
build
enhanced
adversarial
samples
to
conduct
advancing
attacks
,
which
will
likely
continue
to
hinder
the
application
of
ai
technology
in
public
safety
and
security
.
therefore
,
using
ai
technology
to
achieve
fair
and
powerful
social
security
monitoring
,
analysis
,
and
governance
may
not
come
true
as
wished
.
in
order
to
ensure
that
ai
technology
is
not
cracked
and
exploited
,
it
is
urgent
to
study
artificial
intelligence
security
and
countermeasures
against
adversarial
attacks
.
at
the
same
time
,
detection
and
defense
accompanying
adversarial
attacks
are
also
areas
that
should
be
developed
in
the
future
.
references
kurakin
,
a.
,
goodfellow
,
i.
and
bengio
,
s.
(2018)
.
adversarial
examples
in
the
physical
world
.
-lrb-
online
-rrb-
arxiv.org
.
available
at
:
https://arxiv.org/abs/1607.02533
-lrb-
accessed
28
jan.
2020
-rrb-
.
stone
,
p.
,
brooks
,
r.
,
brynjolfsson
,
e.
,
calo
,
r.
,
etzioni
,
o.
,
hager
,
g.
,
...
&
leyton-brown
,
k.
(2016)
.
artificial
intelligence
and
life
in
2030
.
one
hundred
year
study
on
artificial
intelligence
:
report
of
the
2015-2016
study
panel
.
stanford
university
,
stanford
,
ca
,
http://ai100
.
stanford
.
edu\/2016-report
.
accessed
:
september
,
6
,
2016
.
thys
,
s.
,
van
ranst
,
w.
and
goedem
,
t.
(2019)
.
fooling
automated
surveillance
cameras
:
adversarial
patches
to
attack
person
detection
.
-lrb-
online
-rrb-
arxiv.org
.
available
at
:
https://arxiv.org/abs/1904.08653
-lrb-
accessed
28
jan.
2020
-rrb-
.
