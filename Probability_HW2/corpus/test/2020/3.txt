the
article
claims
that
ai
is
shifting
toward
building
systems
that
can
effectively
collaborate
with
people
so
that
people
are
able
to
develop
interactive
and
well-rounded
ways
to
teach
robots
and
enable
them
to
benefit
us
more
-lrb-
2015
study
panel
,
p.
9
-rrb-
.
i
want
to
challenge
this
viewpoint
because
firstly
we
now
can
not
teach
machines
all
things
we
want
them
to
acquire
and
help
them
to
be
as
good
as
we
want
,
and
secondly
people
do
not
show
enough
trusts
to
these
machines
so
without
adopting
ai
,
ai
fails
to
benefit
people
as
we
thought
.
the
performances
of
ai
are
not
as
good
as
developers
expected
to
benefit
the
society
.
for
example
,
the
robot
vacuum
cleaners
are
designed
to
free
people
from
cleaning
their
houses
and
save
their
time
.
however
,
these
cleaners
are
restricted
to
localized
flat
areas
and
can
not
go
up-and-down
stairs
-lrb-
2015
study
panel
,
p.
24
-rrb-
.
for
education
,
teaching
robots
created
for
use
in
k-12
schools
do
not
show
any
evidence
of
improvements
in
students
'
academic
performance
-lrb-
2015
study
panel
,
p.
31
-rrb-
.
therefore
,
the
performances
of
ai
applications
are
not
good
enough
and
their
designers
fail
to
teach
them
everything
they
want
.
furthermore
,
one
of
the
purposes
of
ai
is
to
solve
the
problems
of
bias
.
but
ai
applications
and
the
data
they
rely
upon
may
reflect
the
biases
of
their
designers
,
which
even
deepens
existing
social
biases
.
for
instance
,
some
speech
recognition
technologies
do
n't
work
well
for
women
and
people
with
accents
,
resulting
in
bias
and
unfairness
to
diverse
groups
in
the
society
-lrb-
2015
study
panel
,
p.
43
-rrb-
.
this
shows
people
do
not
realize
their
goal
of
reducing
bias
by
teaching
machines
.
hence
,
we
can
not
teach
machines
everything
and
make
them
to
benefit
the
society
as
much
as
we
desire
.
additionally
,
it
's
always
a
challenge
to
build
trusts
between
human
and
machines
.
first
,
there
are
ethical
issues
associated
with
ai
.
privacy
is
a
common
problem
that
public
concerns
.
ai
technologies
sometimes
reveal
people
's
personal
information
and
private
data
.
according
to
the
article
,
the
vision
of
a
network
of
connected
vehicles
enables
us
to
reach
a
high
level
of
safety
in
driving
with
car-to-car
communication
.
however
,
to
realize
this
,
advanced
technologies
such
as
sensing
capabilities
and
adoption
of
drones
require
a
lot
of
individual
's
private
data
such
as
personal
information
of
the
drivers
and
their
cars
,
real-time
locations
of
their
cars
while
driving
,
and
the
routes
of
traveling
,
which
affects
the
safety
of
their
private
data
.
the
issue
of
privacy
and
the
risk
of
divulging
personal
information
create
barriers
for
people
to
trust
ai
.
second
,
the
emergence
of
ai
also
causes
the
lack
of
jobs
in
the
market
.
based
on
the
article
,
digital
technologies
affect
workers
more
in
the
skilled
middle
,
such
as
travel
agents
,
rather
than
the
very
high-skilled
or
low-skilled
work
.
since
workers
that
fall
into
the
middle
level
are
the
majority
,
they
are
afraid
of
being
marginalized
in
workplace
.
hence
,
this
fear
causes
distrust
of
ai
technologies
in
the
workplace
.
these
distrusts
result
in
people
's
unwillingness
to
adopt
ai
,
impeding
the
benefits
ai
brings
.
overall
,
i
disagree
with
the
idea
that
people
can
always
develop
ways
to
teach
machines
to
enable
them
to
benefit
the
society
because
at
least
nowadays
people
can
not
teach
machines
everything
they
want
and
benefit
people
in
all
aspects
and
many
people
refuse
to
trust
ai
due
to
different
reasons
such
as
ethical
issues
so
ai
wo
n't
give
the
public
as
many
benefits
as
the
article
states
.
designers
today
should
focus
more
on
improving
the
performances
of
ai
applications
and
building
trusts
between
human
and
ai
to
let
ai
benefit
the
society
well-roundly
.
references
2015
study
panel
.
(2016)
.
``
one
hundred
year
study
on
artificial
intelligence
-lrb-
ai100
-rrb-
''
.
retrieved
from
https://ai100.stanford.edu/
