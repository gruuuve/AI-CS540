in
this
new
era
of
information
,
the
overall
public
knowledge
of
technology
has
increased
rapidly
,
and
we
have
witnessed
an
explosion
of
time
,
effort
,
and
resources
being
allocated
to
technological
advancement
.
with
these
recent
developments
,
artificial
intelligence
has
slowly
begun
to
be
implemented
in
society
.
one
of
the
many
ways
in
which
artificial
intelligence
has
been
put
into
action
is
through
transportation
.
some
of
the
ways
transportation
has
been
altered
include
gps
systems
and
auto
sensors
for
blind
spots
and
even
self
driving
cars
.
while
these
technological
progressions
have
made
the
lives
of
citizens
much
easier
,
they
have
certainly
sparked
some
ethical
controversy
.
in
the
article
``
artificial
intelligence
in
life
in
2030
''
,
the
study
panel
discusses
the
impact
that
artificial
intelligence
has
had
and
will
have
on
our
society
.
the
study
panel
understands
that
these
technologies
will
lead
to
government
regulation
.
in
the
article
,
the
panel
calls
for
society
and
its
leaders
to
treat
these
implementations
leniently
,
and
place
responsibility
on
the
implementers
,
yet
trust
that
artificial
intelligence
truly
will
do
less
harm
than
the
congruent
human
controlled
technology
.
however
,
it
is
important
to
acknowledge
that
the
article
oversimplifies
the
legal
and
ethical
repercussions
that
will
result
when
mistakes
inevitably
occur
.
in
the
article
,
it
is
pointed
out
that
artificial
intelligence
products
go
through
rigorous
testing
and
training
phases
where
they
are
introduced
to
various
stimuli
and
these
products
``
learn
''
how
to
react
.
nevertheless
,
it
is
impossible
for
these
training
phases
to
prepare
a
system
for
every
single
possible
situation
.
therefore
,
these
systems
could
most
likely
be
deluded
in
ways
that
humans
would
not
.
until
artificial
intelligence
systems
are
completely
self
aware
,
they
will
serve
as
a
potential
liability
to
society
,
whether
it
creates
dangerous
conditions
or
just
simply
does
not
complete
its
assigned
task
.
in
these
cases
,
it
actually
becomes
less
safe
and
less
efficient
for
artificial
intelligence
to
be
implemented
in
society
.
if
these
technologies
are
going
to
be
embedded
in
more
important
daily
routines
,
such
as
driving
and
transportation
,
they
need
to
be
fully
able
to
react
as
a
human
would
,
or
ideally
,
better
than
a
human
would
.
one
counterargument
is
that
it
shall
be
a
task
of
the
manufacturers
to
design
procedures
that
enhance
the
ability
of
humans
to
understand
artificial
intelligence
systems
.
the
article
also
mentions
that
participating
in
their
use
may
help
build
trust
and
prevent
drastic
failures
.
placing
blame
and
responsibility
on
the
creators
of
machinery
is
the
moral
and
proper
solution
,
although
it
is
ambitious
.
also
,
the
article
highlights
the
idea
that
,
``
rather
than
``
more
''
or
``
stricter
''
regulation
,
policies
should
...
and
foster
broad
corporate
and
civic
responsibility
for
addressing
critical
societal
issues
raised
by
these
technologies
.
''
in
the
event
that
something
goes
wrong
,
how
would
it
truly
be
known
who
is
at
fault
?
this
is
the
same
ideology
as
insurance
companies
.
you
pay
insurance
companies
money
,
and
then
when
you
need
their
help
they
will
provide
you
with
financial
support
.
however
,
this
all
looks
good
on
paper
and
does
not
always
work
out
fairly
.
large
corporations
can
claim
that
users
were
provided
with
the
tools
and
opportunity
to
learn
how
to
operate
and
interact
with
the
technology
,
and
that
a
given
incident
will
not
be
their
fault
.
therefore
,
a
consumer
that
is
placed
in
danger
due
to
a
technological
malfunction
will
be
out
of
luck
.
