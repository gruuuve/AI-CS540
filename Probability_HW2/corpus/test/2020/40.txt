``
the
stanford
one
hundred
year
study
on
artificial
intelligence
2016
report
''
provides
an
abundance
of
incredible
implementations
of
artificial
intelligence
in
the
modern
era
.
following
this
,
it
calls
on
these
examples
and
urges
for
an
artificial
intelligence
revolution
of
sorts
,
arguing
for
increased
funding
and
trust
in
these
specified
systems
.
my
main
issues
with
this
paper
rest
entirely
in
this
second
part
-lrb-
or
i
guess
the
third
part
,
if
we
're
going
by
how
the
article
is
structured
-rrb-
.
one
of
the
more
major
points
this
article
raises
,
and
fails
to
offer
a
direct
solution
to
,
is
the
ethical
stigmas
and
lack
of
proof
for
ai
's
usefulness
,
especially
in
its
call-to-action
.
the
question
is
framed
mainly
in
the
second
step
of
the
authors
'
three
step
solution
to
improve
ai
development
,
yet
is
left
unsolved
.
however
,
i
feel
like
this
ailed
by
the
following
step
,
where
the
authors
call
for
an
increased
funding
for
studying
the
societal
impacts
of
ai
,
which
-lrb-
unintentionally
-rrb-
provides
a
complete
solution
to
their
previous
point
,
buts
completely
removes
the
need
to
mention
it
in
the
first
place
.
regarding
the
main
complaint
raised
,
i
was
mainly
set
off
by
the
second
step
in
the
authors
'
``
process
for
ai
revolution
.
''
in
this
step
,
the
authors
stated
we
should
``
remove
the
perceived
and
actual
impediments
to
research
on
the
fairness
,
security
,
privacy
,
and
social
impacts
of
ai
systems
.
''
this
step
is
heavily
reliant
on
the
proof
of
success
for
other
ai
,
as
well
as
the
general
public
's
view
on
artificial
intelligence
as
both
safe
and
beneficial
,
as
those
are
the
two
things
that
can
push
political
change
,
with
proof
shaping
public\/lawmakers
'
opinions
-lrb-
alternatively
:
lobbying
-rrb-
.
this
statement
is
somewhat
important
,
but
is
incredibly
redundant
,
especially
when
your
next
point
is
a
call
for
increased
funding
for
studying
societal
impacts
,
which
is
something
that
will
almost
definitely
increase
the
rate
of
ai
's
acceptance
by
putting
the
field
in
a
less
publicly-rejectable
position
.
in
short
,
i
believe
that
ai
is
already
a
major
part
of
several
fields
,
and
that
investors
see
its
importance
.
the
public
will
accept
the
changes
given
proof
of
the
technology
's
success
,
which
comes
with
time
,
and
your
next
step
completely
negates
the
need
for
you
to
include
this
point
in
the
first
place
.
on
the
call
for
increased
funding
for
the
study
of
societal
impacts
,
i
feel
like
this
step
almost
completely
encapsulates
the
reasoning
for
the
previous
point
,
and
provides
a
complete
and
functional
solution
to
the
problems
raised
there
,
while
trying
to
answer
a
different
set
of
problems
.
by
putting
money
into
understanding
the
culture
surrounding
ai
and
its
effects
on
society
,
we
can
further
understand
the
problems
it
raises
,
allowing
us
to
devise
solutions
to
minimize
those
impacts
.
by
minimizing
negative
outcomes
-lrb-
by
knowing
what
negative
outcomes
to
minimize\/what
decisions
should
be
prioritized
-rrb-
,
the
technology
will
socially
advance
further
,
and
will
become
publicly
accepted
more
quickly
,
which
is
the
main
problem
with
the
previous
step
-lrb-
speed
of
adoption
-rrb-
.
however
,
the
wording
surrounding
this
step
leads
me
to
believe
that
it
was
n't
intended
as
a
solution
to
the
problems
raised
in
the
second
step
,
which
points
to
the
idea
that
they
had
no
intended
pathway
to
resolve
the
issues
raised
beforehand
.
in
summary
,
i
do
not
believe
that
step
two
is
necessary
in
the
slightest
,
and
simply
increasing
the
ease
of
access
to
ai
education\/governance
and
increased
funding
for
the
impacts
of
ai
are
sufficient
for
the
field
to
grow
-lrb-
\/
continue
to
grow
at
its
current
rate
-rrb-
.
