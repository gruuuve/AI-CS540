extensive
use
of
artificial
intelligence
,
or
ai
,
has
been
expected
to
improve
public
safety
.
police
officers
are
using
it
to
predict
crime
.
in
practice
,
the
factors
which
are
used
to
predict
crime
might
raise
discrimination
problems
.
in
the
article
artificial
intelligence
and
life
in
2030
,
the
author
believes
that
policing
prediction
will
not
enhance
racial
discrimination
.
``
but
well-developed
ai
prediction
tools
have
the
potential
to
actually
remove
or
reduce
human
bias
,
rather
than
reinforcing
it
,
and
research
and
resources
should
be
directed
toward
ensuring
this
effect
.
''
however
,
this
is
not
true
due
to
the
following
reasons
.
first
,
parameters
used
to
predict
crime
can
include
ethnic
implicitly
rather
than
explicitly
.
in
chicago
,
demographic
data
have
shown
that
the
percentage
of
black
is
higher
in
the
financially
insufficient
groups
,
compared
to
other
ethnic
groups
.
given
the
existence
of
regions
that
are
occupied
by
largely
the
same
ethnic
group
,
the
crime
predicting
tool
can
develop
the
address
of
the
citizen
as
a
parameter
and
rate
people
live
in
those
areas
more
likely
to
conduct
a
crime
.
as
a
result
,
the
ethnic
group
is
used
as
an
implicit
parameter
.
people
may
argue
that
the
address
of
citizens
is
relatively
permanent
.
since
artificial
intelligence
is
more
inclined
to
use
the
status
of
the
citizen
,
such
as
postures
or
gaits
,
to
predict
,
the
tool
can
be
designed
so
that
no
permanent
parameters
are
used
.
however
,
the
current
status
can
raise
racial
discrimination
,
as
well
.
some
postures
and
gaits
are
more
likely
to
be
seen
in
certain
groups
.
for
example
,
hip-hop
culture
is
home
to
postures
that
are
almost
exclusive
.
if
artificial
intelligent
tools
use
the
posture
as
a
parameter
,
discrimination
toward
minorities
can
be
constructed
and
ensured
by
values
in
the
computer
running
,
which
can
be
cracked
and
propagandized
.
therefore
,
training
crime
prediction
tools
based
on
an
artificial
intelligence
algorithm
to
find
parameters
can
raise
social
problems
by
enhancing
discrimination
.
second
,
the
potential
of
artificial
intelligence
to
predict
crime
is
limited
,
because
that
the
factors
useful
to
predict
crime
are
limited
,
and
the
scheme
of
artificial
intelligence
for
action
detection
can
easily
be
cracked
.
researches
have
shown
that
there
is
no
significant
difference
in
prediction
precision
between
using
two
factors
versus
using
forty-one
factors
.
the
two
parameters
being
considered
are
simply
age
and
criminal
history
,
in
research
by
the
public
safety
assessment
.
employing
additional
variables
to
crime
prediction
will
not
significantly
increase
the
precision
since
crime
actions
can
be
random
and
not
predictable
.
besides
,
since
action
detections
are
based
on
convolutional
neural
networks
,
it
can
be
easily
cracked
by
simply
pasting
an
image
of
a
person
.
studies
have
shown
that
not
only
the
action
can
not
be
detected
,
but
the
person
standing
in
front
of
the
camera
can
not
be
recognized
as
a
person
.
the
idea
of
cracking
down
artificial
intelligence
is
because
that
image
recognition
is
based
on
edges
.
an
image
of
a
person
shares
exactly
the
same
edges
with
a
real
person
;
therefore
,
it
creates
significant
problems
for
the
algorithm
.
in
conclusion
,
using
artificial
intelligence
to
predict
crime
can
enhance
bias
,
contrary
to
the
argument
in
artificial
intelligence
and
life
in
2030
.
the
role
of
technology
is
to
serve
and
enhance
lives
instead
of
putting
everyone
under
surveillance
.
artificial
intelligence
should
be
our
friend
,
guard
,
not
our
judge
.
