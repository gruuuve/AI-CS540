in
the
stanford
one
hundred
year
study
of
artificial
intelligence
,
the
authors
reference
a
report
saying
self-driving
vehicles
will
be
widely-adopted
by
the
year
2020
.
they
point
to
accomplishments
in
the
field
such
as
googles
self-driving
car
and
tesla
s
semi-autonomous
cars
as
proof
of
the
rapid
growth
self-driving
cars
.
i
challenge
their
assertion
that
self-driving
cars
will
be
so
quickly
adopted
within
the
next
couple
years
.
so
far
self-driving
cars
have
avoided
any
large
negative
press
for
accidents
but
a
tragedy
happening
is
almost
inevitable
especially
as
they
become
more
common
on
the
road
.
regardless
of
whether
the
autonomous
vehicle
is
to
blame
,
prolonged
,
intense
negative
coverage
could
do
significant
damage
to
the
market
.
an
example
is
the
recent
fatality
that
occurred
with
a
tesla
semi-autonomous
vehicle
.
a
semi-truck
pulled
out
in
front
of
the
car
which
could
not
sense
it
due
to
the
reflection
off
the
white
truck
.
even
though
the
accident
was
the
fault
of
the
semi
,
the
average
person
following
the
story
immediately
sees
that
a
human
person
would
have
avoided
the
accident
.
one
negative
story
can
completely
erase
any
real
safety
benefits
self-driving
cars
provide
by
planting
in
consumers
minds
that
a
tragedy
would
have
been
avoided
with
a
human
driver
.
this
effect
is
very
important
to
an
application
such
as
driving
where
the
majority
of
people
believe
they
are
safe
drivers
.
safety
is
an
important
factor
in
buying
a
car
and
people
are
unlikely
to
purchase
a
car
they
feel
is
unsafe
.
i
believe
such
an
event
could
potentially
push
back
sales
of
self-driving
cars
several
years
until
manufactures
can
convince
the
public
that
ai
drivers
are
superior
to
humans
.
another
effect
of
a
tragedy
would
be
to
increase
regulations
on
self-driving
cars
.
regulations
,
while
possibly
increasing
public
belief
in
safety
,
would
certainly
limit
the
innovation
within
the
industry
.
regulations
passed
after
a
tragedy
would
almost
certainly
be
passed
quickly
without
proper
consideration
to
the
effects
.
the
best
way
for
self-driving
car
manufacturers
to
avoid
this
situation
is
to
be
proactive
and
push
for
regulations
that
provide
a
foundation
for
the
ethics
and
safety
of
a
self-driving
vehicle
while
leaving
intact
the
motivators
for
innovation
.
without
regulations
and
industry
standards
,
it
could
create
a
race
to
the
bottom
in
terms
of
ethics
.
a
good
example
is
the
decision
a
self-driving
car
needs
to
make
if
a
crash
is
inevitable
.
the
ethical
decision
would
be
the
one
that
hurts
the
least
amount
of
people
often
times
resulting
in
the
passenger
of
the
car
being
hurt
.
however
without
regulations
,
there
is
nothing
to
stop
a
company
from
programming
cars
to
always
protect
their
passengers
.
such
cars
would
certainly
sell
better
with
consumers
although
they
are
less
safe
and
could
result
in
more
fatalities
on
the
road
.
this
example
illustrates
the
need
to
have
adequate
regulations
and
industry
standards
in
place
to
minimize
the
potential
for
tragedy
and
policies
that
could
turn
the
public
away
from
self-driving
cars
.
although
i
expect
the
usage
of
self-driving
cars
to
increase
in
the
coming
years
,
wide
scale
adoption
by
2020
is
certainly
a
long
shot
.
regulations
take
significant
time
to
bargain
over
and
pass
,
and
self-driving
manufacturers
need
to
prepare
to
deal
with
the
negative
press
of
the
first
large
scale
tragedy
.
these
problems
certainly
can
and
will
be
overcome
,
however
it
will
not
happen
in
the
next
four
years
.
