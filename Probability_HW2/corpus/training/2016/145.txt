the
review
picks
healthcare
among
other
domains
to
examine
ai
's
impact
.
i
agree
that
in
the
future
ai
will
possibly
help
advance
the
field
of
healthcare
,
but
i
disagree
with
the
review
's
point
of
view
over
how
ai
will
achieve
this
in
the
clinical
setting
.
the
review
believes
that
ai
will
function
as
an
assistance
to
doctors
and
help
come
up
with
different
correlations
based
on
patient
data
.
i
believe
that
this
will
not
serve
that
much
help
to
doctors
or
produce
more
reliable
diagnoses
to
patients
.
the
problem
with
this
thought
about
utilizing
ai
in
healthcare
lies
in
the
definition
of
a
doctor
's
job
.
the
job
of
a
doctor
is
to
listen
to
patients
,
examine
them
,
and
evaluate
their
claims
to
come
up
with
a
diagnosis
.
in
that
sense
,
whatever
the
patient
says
is
considered
as
a
claim
till
proven
or
disproven
by
examination
.
so
this
will
rule
out
the
patient
filling
out
any
information
for
such
an
ai
system
as
useful
,
especially
that
doctors
relay
a
lot
on
first
hand
examination
of
patients
.
so
once
a
doctor
examines
the
patient
and
has
a
set
of
conditions
,
the
doctor
will
start
to
evaluate
them
to
come
up
with
a
correlation
and
then
a
diagnosis
.
in
most
cases
with
clear
indicators
,
such
a
process
is
very
clear
and
easy
for
any
doctor
to
follow
.
so
in
this
case
having
the
doctor
feed
all
the
information
available
to
an
ai
system
will
become
a
mundane
task
that
will
slow
the
doctor
's
job
down
.
problems
arise
though
when
a
case
is
not
clear
,
in
the
sense
that
the
same
set
of
conditions
could
be
attributed
to
two
or
more
different
diagnoses
.
the
doctor
's
next
step
regarding
this
uncertainty
will
be
the
path
of
least
harm
to
the
patient
.
if
it
is
possible
without
subjecting
the
patient
to
any
harm
,
the
doctor
will
ask
for
more
examination
to
gain
more
information
and
come
up
with
a
diagnosis
.
the
other
option
would
be
to
go
along
with
another
diagnosis
and
see
how
the
patient
will
respond
to
its
treatment
.
depending
on
the
doctor
and
hospital
,
this
will
either
be
discussed
among
several
doctors
or
not
and
or
the
patient
.
either
way
,
this
is
where
a
significant
part
of
medical
mistakes
originates
.
in
this
trade-off
scenario
of
the
diagnosis
process
having
an
ai
system
is
not
going
to
serve
that
much
help
except
for
retrieving
data
that
the
doctor
can
retrieve
easily
.
both
the
ai
system
and
doctor
will
know
the
harms
and
benefits
of
the
next
step
and
based
on
it
decide
on
what
to
recommend
.
another
type
of
problem
is
caused
by
flawed
examination
.
flawed
examinations
could
happen
due
to
various
reasons
from
inexperienced
doctors
to
contaminated
samples
and
equipment
error
.
if
at
any
point
,
a
flawed
examination
leads
to
a
diagnosis
,
the
doctor
will
not
realize
till
the
patient
is
either
harmed
already
or
is
not
being
responsive
to
treatment
and
thus
their
case
is
getting
worse
.
the
reliability
of
the
examination
process
is
a
nontrivial
problem
that
doctors
try
to
minimize
as
much
as
possible
.
nonetheless
,
if
the
problem
arises
,
given
that
the
information
was
flawed
to
begin
with
,
neither
the
doctor
or
an
ai
system
would
be
able
to
prevent
it
from
happening
.
