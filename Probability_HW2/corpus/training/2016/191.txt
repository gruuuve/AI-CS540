a
prominent
theme
in
stanford
's
``
artificial
intelligence
and
life
in
2030
''
is
the
optimism
of
ai
's
potential
.
almost
every
facet
of
life
has
potential
to
be
improved
by
artificial
intelligence
,
from
self-driving
cars
to
senior
care
,
and
the
report
does
an
excellent
job
of
summarizing
how
each
industry
can
benefit
from
artificial
intelligence
.
so
rather
than
address
one
industry
or
application
,
this
paper
will
focus
more
on
the
problems
with
the
means
they
use
getting
to
the
positive
effects
they
preach
;
the
massive
amounts
of
data
utilized
and
what
that
means
in
a
world
with
increasingly
powerful
ai
.
while
the
benefits
of
smarter
,
better
artificial
intelligence
are
evident
-
reduced
automotive
accidents
,
better
healthcare
and
disease
detection
to
name
a
few
-
this
report
at
times
glosses
over
the
potential
dangers
of
computing
systems
having
this
much
power
and
data
.
the
report
itself
outlines
the
shift
from
intelligent
systems
to
systems
that
are
human-aware
and
trustworthy
,
and
in
the
next
paragraph
talks
about
its
growth
supported
by
``
wide-spread
,
web-based
data
gathering
.
''
the
issue
,
it
states
,
lies
in
creating
more
advance
systems
that
``
will
help
ai
to
advance
more
deeply
into
the
realm
of
learning
about
and
executing
actions
in
the
real
world
''
while
also
giving
these
ai
access
to
incredible
amounts
of
data
.
indeed
,
many
companies
are
valued
so
highly
because
they
have
access
to
an
ungodly
amount
of
personal
data
about
their
users
and
their
habits
,
from
shopping
to
eating
to
vacationing
.
the
moral
objections
many
individuals
have
made
to
companies
like
google
and
facebook
performing
data
mining
and
collection
on
their
own
customers
have
been
,
in
part
,
mitigated
by
the
human
attachment
to
the
data
;
at
the
end
of
the
day
humans
make
the
decisions
,
even
if
the
ai
does
the
analysis
.
creating
artificial
intelligence
that
both
has
unprecedented
access
to
this
data
and
also
acts
in
the
interests
of
ethics
and
morals
creates
situations
with
larger
consequences
as
we
place
ai
in
more
prominent
roles
.
for
example
,
an
ai
that
has
access
to
an
entire
city
's
infrastructure
can
make
decisions
on
a
large
scale
when
,
inevitably
,
its
learning
capabilities
became
proactive
instead
of
reactive
.
this
report
seems
to
focus
on
the
good
and
gloss
over
the
bad
,
at
times
referring
to
the
public
perception
and
legal
hurdles
as
negatives
when
they
may
bring
up
legitimate
concerns
-lrb-
such
as
data
privacy
in
the
21st
century
.
-rrb-
it
does
bring
up
some
ethical
questions
in
the
context
of
automated
driving
with
choosing
who
gets
to
live
in
a
split-second
decision
,
yet
only
devotes
one
sentence
to
that
ethical
question
.
and
while
other
areas
of
focus
do
n't
get
quite
as
life-and-death
,
they
acknowledge
ai
can
fundamentally
change
the
context
of
a
normal
life
situation
,
yet
do
n't
see
the
problematic
questions
involved
with
rapid
advancement
.
another
section
eagerly
talks
of
the
potential
of
public
safety
and
security
in
the
face
of
public
trust
,
even
using
the
phrase
``
assuming
careful
deployment
''
,
which
is
never
elaborated
upon
.
these
are
the
types
of
questions
that
should
be
asked
simultaneously
with
research
and
development
,
not
as
studies
or
after
the
product
has
been
implemented
.
the
conclusion
addresses
some
concerns
,
including
``
system
mistakes
''
,
privileged
access
to
the
benefits
and
privacy
,
but
the
three
policy
recommendations
that
follow
do
n't
adequately
address
the
moral
questions
of
ai
.
governmental
awareness
and
social
research
will
not
be
enough
if
the
developing
sectors
and
companies
are
researching
and
creating
at
the
speed
of
light
with
no
regard
for
the
consequences
.
it
will
take
an
active
,
conscious
effort
-
one
not
entirely
seen
in
this
report
-
for
safe
innovation
.
