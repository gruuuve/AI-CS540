the
stanford
's
artificial
intelligence
study
panel
suggests
three
general
policy
recommendations
to
address
the
concerns
about
the
individual
and
societal
implications
of
rapidly
evolving
ai
technologies
.
i
disagree
with
the
three
recommendations
that
were
proposed
.
the
first
recommendation
is
to
define
a
path
towards
accruing
technical
expertise
in
ai
at
all
levels
of
government
.
the
second
recommendation
is
to
remove
the
impediments
to
research
on
the
fairness
,
security
,
privacy
,
and
social
impacts
of
ai
systems
.
third
,
is
the
recommendation
to
increase
public
and
private
funding
for
studies
of
the
societal
impacts
of
ai
.
these
proposed
general
policy
recommendations
are
too
oriented
on
the
research
perspective
of
the
societal
impacts
of
ai
,
and
none
actually
address
or
solve
the
issues
that
may
occur
if
ai
becomes
integrated
in
the
every
day
life
of
our
public
.
my
three
proposed
general
policies
include
the
following
.
first
,
make
computer
science
a
required
core
skill
and
subject
area
to
be
learned
in
public
schools
,
and
begin
teaching
the
subject
within
the
students
first
year
of
schooling
-lrb-
first
grade
-rrb-
.
secondly
,
create
standards
to
answer
ethical
concerns
of
ai
before
there
is
a
need
for
those
standards
to
exist
.
last
,
put
laws
in
place
that
hold
programmers
accountable
for
any
crucial
mistakes
that
are
made
by
ai
.
with
these
three
recommendations
,
we
may
better
prepare
the
public
for
the
flood
of
ai
technologies
to
come
.
in
december
of
2013
,
chicago
mayor
rahm
emanuel
proposed
a
plan
to
add
computer
science
to
the
core
curriculum
subjects
taught
in
public
schools
.
his
reasoning
was
to
``
ensure
that
our
graduates
are
proficient
in
the
language
of
the
21st
century
so
that
they
can
compete
for
jobs
of
the
future
''
.
as
ai
technologies
continue
to
rise
,
we
are
going
to
need
a
rising
amount
of
our
public
workforce
to
be
able
to
build
these
technologies
.
by
requiring
computer
science
to
be
taught
in
public
schools
starting
in
first
grade
,
we
will
not
only
ensure
that
our
public
will
be
prepared
to
take
on
jobs
related
to
ai
after
graduation
,
but
we
will
also
ensure
that
the
public
has
some
knowledge
and
opinion
on
how
that
ai
is
built
or
used
in
their
societies
.
a
man
who
put
too
much
confidence
in
tesla
's
self
driving
system
experienced
a
fatal
crash
in
may
of
2016
after
his
model
s
crashed
into
a
tractor-trailer
.
now
,
imagine
if
that
tractor-trailer
was
a
group
of
pedestrians
.
who
is
the
car
supposed
to
save
?
there
are
ethical
decisions
that
must
be
made
involving
ai
accidents
that
result
in
human
fatalities
.
standards
must
be
created
to
answer
these
ethical
concerns
before
there
is
a
need
for
those
standards
to
exist
.
for
this
example
,
we
must
create
some
sort
of
standard
procedure
for
how
to
handle
a
driver
vs
pedestrian
fatal
scenario
in
an
autonomous
vehicle
,
before
autonomous
vehicles
are
even
created
themselves
.
branching
off
the
idea
of
creating
standards
procedures
for
ethical
concerns
,
brings
about
a
curiosity
of
who
to
hold
accountable
when
ai
fails
.
in
order
to
drive
excellence
in
the
creation
of
ai
technologies
,
we
must
hold
the
programmers
themselves
responsible
for
the
mistakes
made
by
the
ai
technologies
they
created
.
by
putting
laws
in
place
to
hold
programmers
responsible
,
we
would
be
able
to
legally
treat
any
ai
technology
as
an
extension
of
the
programmer
.
this
would
create
a
desire
in
the
programmer
to
create
the
best
possible
product
they
can
,
and
think
thoroughly
about
what
consequences
could
occur
in
the
event
of
their
product
failing
.
these
recommendations
will
better
address
the
concerns
about
the
individual
and
societal
impacts
of
ai
technologies
.
