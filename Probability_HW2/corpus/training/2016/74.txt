title
:
checking
bias
in
artificial
intelligence
tools
.
the
authors
of
this
report
have
taken
a
stand
that
``
well-deployed
ai
prediction
tools
have
potential
to
provide
new
kinds
of
inferences
that
may
be
used
to
detect
,
remove
or
reduce
human
bias
''
.
while
it
seems
like
ai
may
appear
unbiased
as
it
strictly
uses
computer
code
to
reach
conclusions
and
so
does
the
argument
that
``
with
careful
design
,
testing
,
and
deployment
,
ai
algorithms
may
be
capable
of
making
less
biased
decisions
than
a
typical
person
''
seem
sound
,
yet
there
are
many
recent
examples
of
well
deployed
ai
tools
which
have
shown
otherwise
behaviors
.
for
instance
google
,
the
company
that
spearheads
ai
researches
in
the
world
with
projects
such
as
deepmind
,
created
products
that
are
accidentally
biased
and
also
found
to
be
racist
.
in
july
2015
,
carnegie
mellon
university
's
computer
scientists
reported
women
were
less
likely
than
men
to
be
shown
ads
on
google
for
jobs
paying
more
than
$
200,000
,
which
is
clearly
a
biased
search
result
.
so
was
the
case
of
microsoft
teenage
chatbot
attempt
called
``
tay
''
whose
algorithm
worked
exactly
as
its
creators
had
planned
,
but
it
still
ended
up
being
biased
,
racist
and
sexist
after
it
was
trained
to
learn
from
humans
.
clearly
these
and
other
examples
of
well
deployed
tools
being
developed
by
top
ai
researchers
in
the
world
seem
to
have
been
struck
by
bias
.
the
report
also
claims
that
``
it
remains
a
deep
technical
challenge
to
ensure
that
the
data
that
inform
ai-based
decisions
can
be
kept
free
from
biases
that
can
lead
to
discrimation
based
on
race\/sexual
orientation
''
.
while
this
statement
seems
true
to
the
extent
that
ai
applications
and
the
data
they
rely
upon
may
reflect
the
biases
of
their
designers
and
users
,
who
specify
the
data
sources
,
it
has
to
be
noted
that
there
has
been
a
growing
debate
on
whether
machine-learning
algorithms
can
themselves
introduce
unintentional
bias
much
like
humans
and
hence
``
data
''
need
not
always
be
blamed
.
a
simple
example
that
comes
to
mind
is
that
if
there
are
multiple
logically
correct
solutions
to
a
certain
problem
and
the
ai
program
simply
chooses
to
show
only
a
particular
solution
to
the
end
user
everytime
.
it
may
be
considered
as
a
biased
answer
by
certain
population
unless
the
program
includes
an
element
of
randomness
to
display
the
different
correct
answers
at
different
times
.
also
it
is
observed
that
in
some
ai
systems
,
the
personal
data
is
used
to
train
a
super
intelligent
ai
and
the
same
is
used
to
train
and
predict
personalized
recommendations
and
has
the
net
effect
of
still
being
right
initially
but
at
the
cost
of
not
being
the
ideal
personalized
system
as
ideally
a
personalized
systems
needs
to
adopt
to
only
the
end-user
's
biases
and
not
biases
of
other
users
.
personalized
systems
and
unbiased
systems
even
though
can
exist
separately
,
often
the
former
employs
bias
in
some
ways
.
finally
,
since
biased
ai
algorithms
are
exacerbating
inequality
in
the
workplace
,
at
home
and
in
our
legal
and
judicial
systems
,
it
is
important
for
ai
researchers
them
with
newer
approaches
.
``
the
irony
is
that
the
more
we
design
artificial
intelligence
technology
that
successfully
mimics
humans
,
the
more
that
a.i.
is
learning
in
a
way
that
we
do
,
with
all
of
our
biases
and
limitations
,
''
venkatasubramanian
ai
researcher
from
university
of
utah
says
.
this
infacts
questions
the
very
definition
of
ai
which
is
defined
in
the
report
``
ai
is
inspired
by
how
people
use
it
to
sense
,
learn
and
reason
''
