the
report
defines
ai
as
a
science
of
computational
technology
that
is
inspired
by
the
ways
people
use
their
nervous
systems
and
bodies
.
this
includes
giving
machines
the
abilities
to
sense
,
learn
,
reason
,
and
take
action
.
some
broad
and
serious
challenges
that
this
technology
raises
include
the
possibilities
of
this
technology
being
a
threat
to
humans
both
physically
and
economically
.
although
this
technology
offers
great
potential
to
improve
daily
life
in
many
aspects
,
the
negative
effects
must
be
evaluated
before
complete
integration
is
implemented
.
healthcare
offers
many
situations
for
the
implementation
of
ai
.
using
ai
technology
within
the
healthcare
field
could
help
to
make
a
diagnosis
,
monitor
patients
,
assist
in
surgery
,
or
manage
healthcare
systems
.
however
,
due
to
the
complexity
of
this
field
and
the
unpredictability
of
some
physiological
processes
,
implementing
ai
in
this
field
is
extremely
challenging
and
sensitive
.
i
believe
,
that
with
the
majority
of
the
situations
where
ai
could
be
used
within
this
field
,
it
is
simply
a
safer
and
more
effective
option
to
utilize
a
human
brain
instead
of
an
artificial
one
.
although
this
article
states
that
ai
would
only
be
used
in
accordance
with
a
doctor
in
diagnosis
situations
,
i
still
believe
that
technology
should
only
give
resources
to
allow
the
doctor
to
make
a
decision
.
physiology
varies
drastically
across
humans
,
and
that
variability
scales
when
multiple
factors
are
being
considered
.
in
order
for
a
machine
to
make
a
correct
decision
,
it
would
need
to
have
an
extremely
high
amount
of
personal
health
information
and
also
a
way
to
process
that
information
.
further
,
gaining
the
trust
of
both
doctors
and
patients
is
necessary
as
well
.
for
example
,
if
a
neural
network
outputs
that
a
patient
has
diabetes
strictly
from
their
symptoms
being
inputted
,
they
most
likely
would
still
undergo
a
blood
test
to
confirm
the
results
of
the
machine
's
output
.
this
raises
the
following
question
:
does
ai
positively
affect
the
diagnosis
process
if
it
's
results
must
still
be
confirmed
?
also
,
this
example
uses
a
disease
that
is
relatively
understood
and
has
a
high
rate
of
successfully
diagnosing
.
if
ai
can
not
be
trusted
in
this
case
,
should
it
be
trusted
when
a
life-threatening
disease
is
being
tested
for
?
finally
,
what
happens
if
ai
outputs
an
incorrect
,
negative
diagnosis
?
does
the
doctor
go
through
the
diagnosis
procedure
regardless
to
confirm
the
results
or
does
the
doctor
trust
the
output
?
if
the
doctor
trusts
the
output
and
the
patient
's
health
is
negatively
affected
,
whose
fault
is
it
?
these
are
all
very
serious
questions
that
must
be
answered
strongly
before
ai
can
be
implemented
into
healthcare
enough
to
make
a
positive
impact
.
at
this
time
the
understanding
of
physiology
does
not
exist
enough
to
prepare
ai
to
make
decisions
well
enough
that
they
can
be
trusted
without
the
opinion
of
a
doctor
.
also
,
like
it
is
stated
in
the
report
,
many
regulations
exist
that
prohibit
methods
of
data
collection
that
could
be
beneficiary
for
the
improvement
of
ai
technology
.
it
is
my
opinion
that
at
this
time
,
the
technology
does
not
exist
to
allow
ai
to
effectively
replace
major
methods
within
the
healthcare
field
.
however
,
this
implementation
should
be
a
focus
for
researchers
for
the
foreseeable
future
as
ai
does
hold
potential
to
improve
the
quality
of
healthcare
.
