-lcb-
rtf1
ansi
ansicpg1252
cocoartf1404
cocoasubrtf470
-lcb-
fonttbl
f0
fswiss
fcharset0
helvetica
;
-rcb-
-lcb-
colortbl
;
red255
green255
blue255
;
-rcb-
margl1440
margr1440
vieww17640
viewh14080
viewkind0
pard
tx720
tx1440
tx2160
tx2880
tx3600
tx4320
tx5040
tx5760
tx6480
tx7200
tx7920
tx8640
pardirnatural
partightenfactor0
f0
fs24
cf0
my
experience
with
ai
before
this
course
is
limited
to
handfuls
of
lectures
,
basic
understanding
of
common
algorithms
and
loyal
patronage
of
'
93the
ai
podcast
with
lex
fridman
'94
'97
i
have
tried
to
dive
into
the
practical
coding
of
deep
neural
nets
but
didn
'
92t
have
luck
with
it
sticking
.
apologies
in
advance
for
any
blatantly
wrong
statements
in
my
below
rebuttal
.
and
perhaps
for
a
bit
more
context
into
my
writing
'97
i
study
computer
science
,
but
am
going
into
fashion
and
textiles
,
and
my
interest
in
ai
comes
from
trying
to
understand
what
it
means
ontologically
for
regular
people
,
as
well
as
a
few
textile
specific
problems
.
i
found
the
reading
to
be
incredibly
acceptable
i.e.
it
was
obviously
written
by
a
panel
of
experts
making
relatively
conservative
guesses
for
the
future
.
that
being
said
,
i
am
always
disappointed
with
the
scope
that
some
experts
predict
ai
will
be
useful
,
my
speculation
-lrb-
in
the
context
of
the
review
-rrb-
is
that
this
is
due
to
an
over-representation
of
deep
learning
and
how
this
frames
future
research
in
ai
,
as
well
as
the
context
of
the
paper
in
that
it
aims
to
simplify
general
aims
of
the
field
,
rather
than
create
more
open
questions
for
lay
readers
.
i
believe
this
point
can
be
illustrated
with
a
few
examples
:
the
review
takes
for
granted
that
something
like
level
5
-lrb-
fully
autonomous
-rrb-
driving
will
be
solved
in
15
years
.
though
many
across
industry
are
pursuing
this
-lrb-
lincoln
,
tesla
,
commaai
-rrb-
i
question
-lrb-
speculatively
,
i
'
92m
just
a
hobbyist
at
this
point
-rrb-
if
deep
reinforcement
learning
will
be
able
to
go
all
the
way
'97
if
the
system
-lrb-
driving
-rrb-
is
closed
enough
to
safely
handle
all
edge
cases
including
novel
circumstances
.
i.e.
will
the
way
that
we
develop
algorithms
now
,
generalize
to
handle
all
situations
without
significantly
changing
the
scope
of
the
problem
by
introducing
sufficiently
many
autonomous
agents
.
my
intuition
here
is
following
some
of
the
zany
behavior
i
see
in
pop
ai
articles
surrounding
flawed
optimization
functions
'85
trivially
,
would
a
car
programmed
to
be
completely
safe
not
ever
drive
anywhere
.
i
think
the
question
i
'
92m
getting
at
is
,
is
there
sufficient
decision
making
capability
found
in
deep
learning
algorithms
,
or
do
researchers
have
to
change
the
way
we
conceive
of
decision
making
to
solve
the
current
set
of
problems
on
the
very
edge
of
ai
-lrb-
generalized
hci
,
-rrb-
.
from
brief
conversations
-lrb-
that
quickly
go
over
my
head
-rrb-
with
neuroscience
researchers
-lrb-
my
gf
-rrb-
i
'
92m
led
to
believe
there
are
'
93better
'94
problem
solving
ethoses
such
as
the
htm
1000
mind
theory
.
i
was
also
disappointed
that
the
paper
skidded
around
the
topics
of
consciousness
,
and
as
an
extension
embodiment
as
fields
of
research
-lrb-
though
it
does
mention
research
into
robotics
-rrb-
'97
perhaps
i
am
wrong
in
thinking
this
is
an
active
field
of
research
-lrb-
i
don
'
92t
really
have
a
sense
of
the
existing
body
of
literature
-rrb-
but
my
understanding
is
that
these
topics
are
the
underlying
meta-driver
for
the
reason
most
researchers
pursue
artificial
intelligence
,
for
lack
of
better
words
the
common
goal
.
further
,
-lrb-
again
speculation
-rrb-
my
belief
is
that
the
most
useful
way
of
communicating
the
importance
of
the
field
to
outsiders
-lrb-
as
well
as
keeping
consistent
interest
'85
and
funding
-rrb-
for
example
,
politicians
historically
are
awful
at
extrapolating
the
underlying
consequences
from
tech
events
e.g.
the
facebook
hearings
-
is
it
perhaps
more
useful
to
communicate
a
bigger
picture
sense
of
the
field
rather
than
current
waves
of
research
-lrb-
that
are
bound
to
change
over
time
-rrb-
