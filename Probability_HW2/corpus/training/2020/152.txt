in
this
article
,
one
idea
is
that
after
ai
brings
a
new
technology
into
the
common
fold
,
people
become
accustomed
to
this
technology
and
then
it
stops
being
considered
ai
,
and
newer
technology
emerges
.
for
example
,
although
deep
blue
astonished
people
in
the
first
place
,
it
is
soon
accused
as
a
collection
of
brute
force
methods
that
is
not
real
intelligence
.
i
do
not
agree
with
idea
.
for
me
the
definition
of
ai
is
rigid
that
people
can
always
draw
a
clear
cut
between
what
is
ai
and
what
is
not
,
like
how
definitions
work
in
biology
or
physics
.
as
defined
in
this
article
,
the
intelligence
is
the
``
quality
that
enables
an
entity
to
function
appropriately
and
with
foresight
in
its
environment
''
,
and
any
human
made
machine
that
achieve
this
function
should
be
considered
as
ai
.
what
level
of
foresight
it
has
and
how
it
is
achieved
do
not
really
matter
as
long
as
this
foresight
in
its
environment
exists
and
this
machine
functions
according
to
such
foresight
,
since
even
an
ant
is
considered
to
have
some
level
of
intelligence
although
it
may
not
do
what
people
usually
consider
as
the
process
of
thinking
.
as
the
result
,
the
definition
of
ai
is
rigid
in
this
way
,
and
it
is
clear
the
deep
blue
should
be
considered
as
ai
since
playing
chess
does
require
the
prediction
of
current
environment
.
how
this
prediction
is
achieved
,
like
so
called
``
a
collection
of
brute
force
methods
''
,
does
not
matter
,
and
whether
or
not
it
beats
the
human
champion
does
not
matter
as
well
.
i
also
do
not
agree
with
the
idea
that
the
massive
usage
of
surveillance
camera
,
drones
,
and
predictive
policy
will
,
and
should
,
be
achieved
in
2035
.
for
me
these
technologies
should
be
restricted
and
the
widely
usage
may
not
be
easily
achieved
even
in
2035
.
will
innocent
people
be
unjustifiably
targeted
remains
a
problem
,
as
the
article
has
mentioned
and
what
has
been
shown
by
so
many
science
fictions
.
the
article
tries
to
solve
this
doubt
by
stating
that
,
with
advanced
ai
technology
,
such
problem
will
not
exist
since
ai
can
even
be
fairer
and
more
unbiased
than
human
.
however
,
if
we
should
use
such
technologies
is
not
simply
a
technical
concern
but
rather
a
moral
issue
sometime
.
the
problem
is
that
should
we
give
ai
the
ability
to
control
,
monitor
,
and
make
judge
of
human
beings
,
even
if
it
is
advanced
enough
to
make
the
mistake
as
few
as
possible
.
such
concerns
,
somehow
like
the
worries
about
gene
modification
,
makes
these
new
techniques
difficult
for
the
public
to
accept
.
privacy
is
another
concern
,
since
events
like
prism
make
people
fear
that
their
privacy
could
be
harmed
by
governments
or
companies
through
these
techniques
.
as
the
result
,
should
we
use
these
ai
technologies
is
still
being
debated
widely
,
and
different
people
give
different
answers
.
for
example
,
china
has
been
using
camera
and
face-identification
in
so
many
places
and
it
turns
out
that
these
techniques
do
reduce
the
crimes
a
lot
.
however
europe
is
now
considering
laws
forbidden
the
use
of
face
identification
in
public
area
,
in
order
to
protect
people
's
privacy
.
with
such
different
attitudes
toward
this
technique
,
it
is
unclear
whether
or
not
it
can
be
widely
accepted
and
used
even
in
2035
,
as
it
is
described
in
this
paper
.
