in
stanford
one
hundred
year
study
on
artificial
intelligence
2016
report
,
the
prediction
within
the
transportation
area
is
worth
further
discussion
.
according
to
the
report
(2016)
,
because
of
the
progress
made
in
autonomous
transportation
,
the
public
will
probably
first
be
asked
to
trust
the
application
of
ai
in
this
domain
as
one
form
of
life-related
task
.
however
,
before
the
awakening
of
public
awareness
,
data-driven
ai
systems
would
be
at
stake
if
the
assumption
of
data
safety
is
breached
.
this
assumption
could
be
violated
in
three
ways
:
incomplete
data
for
current
use
,
insufficient
data
for
training
during
the
transition
from
almost
fully
manual
driving
to
almost
fully
autonomous
driving
,
and
incapability
of
data
currently
in
use
to
predict
data
safeness
in
the
future
.
firstly
,
what
data
the
industries
have
applied
to
their
products
could
be
problematic
.
autonomous
vehicles
,
which
are
frequently
mentioned
in
the
report
(2016)
,
rely
on
deep
neural
networks
to
perceive
surroundings
and
conduct
planning
accordingly
.
these
artificial
networks
are
the
foundation
of
tesla
vision
,
a
necessary
component
of
the
autonomous
driving
system
of
tesla
,
autopilot
-lrb-
n.d.
-rrb-
.
however
,
these
artificial
networks
seem
still
unreliable
under
certain
circumstances
.
for
example
,
according
to
one
research
done
by
tencent
keen
security
lab
,
tesla
's
autopilot
system
could
be
deceived
by
only
interference
stickers
on
the
road
,
which
makes
the
vehicle
enter
into
the
reverse
lane
(2019)
.
because
autopilot
system
recognizing
roads
by
image
input
,
such
false
judgment
made
by
this
system
could
partly
reflect
that
visionary
task
solutions
based
on
deep
networks
are
defective
.
such
failure
could
probably
be
attributed
to
incomplete
data
input
during
the
network
's
training
period
so
that
it
can
not
identify
even
simple
distractions
from
the
researches
.
data
in
use
might
not
be
safe
.
secondly
,
during
the
transition
to
cities
full
of
autonomous
vehicles
,
other
techniques
would
probably
be
necessary
to
inform
autonomous
driving
systems
.
in
reality
,
there
are
less
frequent
situations
that
generate
fewer
data
.
such
inadequacy
of
data
would
be
severe
during
the
evolution
of
autonomous
driving
.
one
example
of
this
could
be
ethical
dilemmas
that
self-driving
cars
must
face
.
given
that
ai
drivers
and
human
drivers
would
coexist
for
some
time
,
ai
drivers
could
respond
to
accidents
faster
compared
to
human
drivers
.
if
an
accident
happens
,
which
would
affect
both
ai
drivers
and
human
drivers
,
and
ais
have
to
decide
which
human
driver
it
``
should
''
hurt
to
save
its
passengers
,
ai
systems
just
can
not
sacrifice
thousands
or
millions
of
lives
to
formulate
a
morally
acceptable
answer
.
if
through
simulation
of
reality
,
then
such
data
augmentation
technique
's
practicability
would
also
need
further
justification
,
which
would
also
cause
questions
of
data
safety
.
something
intrinsic
has
to
be
taught
to
ai
,
but
not
in
the
form
of
data
cramming
teaching
.
therefore
,
there
would
be
cases
when
data
is
just
simply
not
enough
to
build
a
robust
system
,
if
human
and
ai
are
going
to
live
and
operate
side
by
side
.
data
could
be
a
way
out
for
some
problems
,
but
not
for
all
.
in
terms
of
those
tricky
problems
such
as
ethical
dilemmas
,
data
could
hardly
be
safe
.
thirdly
,
using
current
data
to
assume
its
usefulness
in
the
future
is
not
persuasive
.
in
the
report
(2016)
,
the
writers
envision
a
future
not
only
full
of
autonomous
cars
,
but
also
intelligent
drones
.
if
data
is
still
the
core
of
systems
of
drones
,
nowadays
data
would
probably
not
be
representative
enough
to
guide
many
flying
objects
in
the
future
because
data
needed
at
that
time
could
have
higher
dimensions
when
flying
objects
have
to
analyze
their
situations
and
make
decisions
in
a
3-d
environment
.
1
.
peter
stone
,
rodney
brooks
,
erik
brynjolfsson
,
ryan
calo
,
oren
etzioni
,
greg
hager
,
julia
hirschberg
,
shivaram
kalyanakrishnan
,
ece
kamar
,
sarit
kraus
,
kevin
leyton-brown
,
david
parkes
,
william
press
,
annalee
saxenian
,
julie
shah
,
milind
tambe
,
and
astro
teller
.
``
artificial
intelligence
and
life
in
2030
.
''
one
hundred
year
study
on
artificial
intelligence
:
report
of
the
2015-2016
study
panel
,
stanford
university
,
stanford
,
ca
,
september
2016
.
doc
:
http://ai100.stanford.edu/2016-report
.
accessed
:
september
6
,
2016
.
2
.
tesla
vision
-lrb-
n.d.
-rrb-
retrieved
from
https://www.tesla.com/autopilot
