unlike
in
the
movies
,
there
is
no
race
of
superhuman
robots
on
the
horizon
or
probably
even
possible
.
and
while
the
potential
to
abuse
ai
technologies
must
be
acknowledged
and
addressed
,
their
greater
potential
is
,
among
other
things
,
to
make
driving
safer
,
help
children
learn
,
and
extend
and
enhance
people
's
lives
.
ai
is
changing
how
people
interact
with
technology
.
many
people
have
already
grown
accustomed
to
touching
and
talking
to
their
smart
phones
.
people
's
future
relationships
with
machines
will
become
ever
more
nuanced
,
fluid
,
and
personalized
as
ai
systems
learn
to
adapt
to
individual
personalities
and
goals
.
north
american
cities
and
federal
agencies
have
already
begun
to
deploy
ai
technologies
in
border
administration
and
law
enforcement
.
by
2030
,
they
will
rely
heavily
upon
them
,
including
improved
cameras
and
drones
for
surveillance
,
algorithms
to
detect
financial
fraud
,
and
predictive
policing
.
as
a
society
,
we
are
now
at
a
crucial
juncture
in
determining
how
to
deploy
ai-based
technologies
in
ways
that
promote
,
not
hinder
,
democratic
values
such
as
freedom
,
equality
,
and
transparency
.
while
the
study
panel
does
not
consider
it
likely
that
near-term
ai
systems
will
autonomously
choose
to
inflict
harm
on
people
,
it
will
be
possible
for
people
to
use
ai-based
systems
for
harmful
as
well
as
helpful
purposes
.
a
most
prevalent
issue
today
is
in
regards
to
gender
bias
in
ai
and
data
science
.
ai
is
said
to
increase
quality
of
life
but
is
currently
perpetuating
gender
stereotypes
.
in
a
real
world
example
,
suggest
to
samsung
's
virtual
personal
assistant
bixby
``
let
's
talk
dirty
''
,
and
the
female
voice
will
respond
with
a
honeyed
accent
:
``
i
do
n't
want
to
end
up
on
santa
's
naughty
list
.
''
ask
the
same
question
to
the
programme
's
male
voice
and
it
replies
``
i
've
read
that
soil
erosion
is
a
real
dirt
problem
.
''
virtual
personal
assistants
--
such
as
bixby
,
alexa
-lrb-
amazon
-rrb-
,
siri
-lrb-
apple
-rrb-
and
cortana
-lrb-
microsoft
-rrb-
--
are
at
the
cutting
edge
of
marketable
artificial
intelligence
-lrb-
ai
-rrb-
.
with
their
female
names
,
voices
and
programmed
flirtatiousness
,
the
design
of
virtual
personal
assistants
reproduces
discriminatory
stereotypes
of
female
secretaries
who
,
according
to
the
gender
stereotype
,
is
often
more
than
than
just
a
secretary
to
her
male
boss
.
it
also
reinforces
the
role
of
women
as
secondary
and
submissive
to
men
.
these
ai
assistants
operate
on
the
command
of
their
user
.
arguably
,
they
also
raise
expectations
for
how
real
women
ought
to
behave
.
it
is
being
increasingly
acknowledged
that
ai
systems
are
often
biased
,
particularly
along
race
and
gender
lines
.
for
example
,
the
recent
recruitment
algorithm
development
by
amazon
to
sort
resumes
for
job
applications
displayed
gender
biases
by
downgrading
resumes
which
contained
the
word
``
women
''
or
which
contained
reference
to
women
's
colleges
.
as
the
algorithm
was
trained
on
historical
data
and
the
preferential
recruitment
of
males
,
it
ultimately
could
not
be
fixed
and
had
to
be
dropped
.
