artificial
intelligence
is
becoming
an
ever
more
important
field
of
study
,
not
only
in
computer
science
,
but
in
all
disciplines
.
its
controversial
technologies
open
debates
that
can
not
be
answered
without
careful
examination
and
thought
on
the
consequences
these
technologies
create
.
throughout
the
report
artificial
intelligence
and
life
in
2030
,
the
authors
discuss
the
important
subsets
of
ai
currently
on
the
forefront
of
research
as
well
as
the
effects
of
the
applications
of
these
fields
will
have
on
the
general
public
.
one
of
the
main
areas
of
discussion
was
the
ethics
of
ai
.
the
report
explains
the
importance
of
developing
sound
policies
that
satisfy
the
general
public
.
it
states
three
policies
that
we
must
invoke
to
even
begin
to
solve
these
debates
.
the
three
polices
are
to
train
the
government
to
be
adept
in
ai
technologies
,
remove
the
laws
that
prevent
research
into
certain
ai
systems
,
and
lastly
increase
funding
into
the
societal
impacts
of
ai
.
these
all
are
great
and
will
help
us
reach
a
state
closer
to
equilibrium
within
the
ethics
of
ai
,
but
i
believe
there
to
be
one
more
necessary
policy
.
i
believe
the
general
public
needs
to
be
taught
that
ai
comes
with
inevitable
and
unsolvable
problems
.
also
,
to
understand
that
to
further
the
benefits
of
ai
we
must
not
get
stunted
by
these
problems
.
the
problem
that
came
to
mind
while
reading
the
report
was
the
autonomous
car
decision
problem
.
the
problem
is
if
an
autonomous
car
is
driving
and
ahead
of
it
a
person
is
crossing
the
street
,
and
has
the
choice
to
either
hit
the
person
,
or
swerve
and
crash
potentially
killing
the
passengers
,
how
do
we
develop
a
policy
for
this
situation
?
the
problem
is
fundamentally
linked
to
the
ethics
of
ai
and
does
not
have
solution
.
either
choice
is
wrong
in
the
eyes
of
the
other
.
but
this
illuminates
my
point
,
to
have
ai
we
must
accept
the
fact
that
decisions
need
to
be
made
to
prevent
the
stagnation
of
the
field
.
just
like
politics
,
ai
will
continually
bring
about
problems
that
different
groups
will
emphatically
disagree
about
.
we
must
adopt
a
machiavellian
viewpoint
,
that
is
,
the
ends
will
justify
the
means
.
if
we
can
see
the
benefits
that
ai
will
provide
,
we
can
not
let
the
inevitable
moral
disagreements
hold
it
back
.
further
,
another
observation
i
made
was
that
to
have
a
successful
ai
system
it
usually
must
be
provided
with
large
amounts
of
data
.
but
this
conflicts
with
the
privacy
and
security
of
our
personal
information
.
if
this
data
is
necessary
to
create
better
ai
for
human
use
,
how
can
we
trust
the
companies
use
of
this
data
?
but
i
think
the
report
answered
this
question
indirectly
.
when
it
examined
the
use
of
ai
for
future
senior
citizens
,
it
touched
upon
how
the
new
elderly
will
have
already
been
exposed
and
gain
a
trust
with
technology
,
so
they
will
be
more
inclined
to
use
technology
in
their
latter
years
.
i
think
as
ai
becomes
readily
available
many
will
accept
the
fact
that
our
personal
data
is
necessary
for
the
ai
to
be
successful
and
trust
the
companies
use
of
it
.
in
my
experience
the
example
of
amazon
s
home
assistant
alexa
comes
to
mind
.
many
at
first
were
skeptical
of
its
constant
listening
and
data
collection
,
but
now
its
hard
to
find
a
home
without
one
-lrb-
or
similar
device
-rrb-
because
of
the
usefulness
of
it
.
ai
is
not
going
away
and
will
continually
develop
challenges
that
will
take
time
to
either
answer
or
accept
.
but
as
the
technology
grows
,
i
believe
the
benefits
will
outweigh
the
challenges
.
