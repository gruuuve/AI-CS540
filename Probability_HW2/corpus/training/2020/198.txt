development
of
artificial
intelligence
-lrb-
ai
-rrb-
in
the
past
100
years
is
explained
and
appraised
in
`
artificial
intelligence
and
life
in
2030
'
.
as
a
reflective
piece
of
report
,
it
proposes
many
existing
difficulties
and
challenges
in
ai
industry
,
including
privacy
violation
,
inequality
in
access
to
technology
and
extension
of
social
bias
.
however
,
beyond
them
,
there
are
other
domains
in
ai
field
that
are
worth
challenging
.
ai
helps
in
public
safety
and
security
,
but
does
this
improvement
is
worth
its
cost
?
in
public
safety
,
ai
is
sometimes
used
to
make
models
and
predictions
.
but
even
accurate
predictions
may
lead
to
bad
result
.
wifire
,
a
cyber-infrastructure
system
,
predicts
wildfire
's
path
in
california
forest
fire
in
real
time
using
ai
algorithm
.
and
the
local
fire
department
arranges
personnel
according
to
current
situation
and
the
ai
prediction
.
it
turns
out
as
a
demonstrated
success
of
ai
in
safety
.
however
,
although
the
prediction
may
be
accurate
enough
,
it
is
not
a
`
sure
'
for
what
is
going
to
happen
.
the
high
accuracy
lowers
people
's
sensitivity
to
other
possibilities
.
the
more
people
trust
ai
,
the
safer
they
feel
with
predictions
and
the
slower
they
will
respond
to
other
unpredicted
situations
.
and
this
is
bad
for
emergency
response
and
is
a
problem
to
solve
in
ai
development
.
when
it
comes
to
a
dangerous
response
system
,
like
a
gun
shooting
detecting
system
,
ai
does
its
great
job
at
citizens
'
cost
.
ai
is
less
likely
to
make
error
than
human
.
it
has
a
shorter
response
time
and
can
identify
danger
more
standardly
,
although
it
may
lack
of
flexibility
compared
to
human
actions
.
problem
of
ai
here
is
that
the
detecting
system
is
like
a
huge
siri
applied
to
the
city
.
siri
is
not
activated
until
owner
of
the
phone
calls
`
siri
'
.
but
it
keeps
listening
all
the
time
for
this
trigger
word
.
and
the
potential
detecting
system
is
always
listening
to
the
city
,
just
like
siri
does
to
the
owner
.
although
the
sounds
wo
n't
be
recorded
until
a
gun
shoot
sound
triggers
the
system
,
possible
foul
play
can
take
advantage
of
the
system
to
listen
to
conversations
illegally
.
just
like
how
surveillance
camera
around
the
city
helps
track
and
catch
criminals
,
there
is
a
cost
of
privacy
to
achieve
higher
safety
.
ai
in
safety
is
based
on
the
idea
of
predictive
action
,
which
is
ethically
under
debate
.
it
is
reported
that
``
the
perpetrator
in
16
%
of
mass
shootings
from
2000
to
2013
displays
concerning
behavior
online
before
the
attack
''
according
to
a
fbi
study
.
though
it
is
impossible
for
human
to
investigate
the
massive
data
online
to
fine
out
the
potential
perpetrators
,
ai
can
achieve
it
.
however
,
after
identification
potential
perpetrators
of
crimes
and
attacks
,
which
principle
should
security
officers
base
on
to
act
to
protect
people
is
an
ethical
question
.
trustworthy
data
from
ai
is
saying
that
some
person
is
going
to
commit
a
crime
,
but
he\/she
is
not
guilty
until
the
very
moment
he\/she
acts
.
in
fact
,
people
can
change
mind
just
in
one
second
.
acting
based
on
ai
predictions
seems
cruel
,
even
just
a
special
online
surveillance
is
a
step
out
of
normal
zone
.
