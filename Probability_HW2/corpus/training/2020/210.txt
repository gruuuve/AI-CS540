ai
and
bias
in
the
article
``
stanford
one
hundred
year
study
on
artificial
intelligence
2016
report
''
,
the
author
-lrb-
s
-rrb-
expresses
many
farsighted
and
thoughtful
opinions
about
the
ai
in
the
current
stage
and
ai
in
the
future
.
however
,
on
page
37
,
the
author
asserts
that
a
well-developed
ai
has
the
ability
to
eliminate
bias
and
discrimination
.
in
my
perspective
,
the
fact
is
just
the
opposite
--
ai
promotes
bias
to
certain
degrees
.
first
of
all
,
the
training
data
comes
with
bias
.
the
essence
of
current
ai
depends
on
considerable
numbers
of
input
training
data
.
unfortunately
,
there
is
nearly
impossible
to
give
consideration
to
both
the
quantity
of
training
data
and
the
proportionality
of
training
data
.
for
example
,
suppose
people
want
to
very
precisely
express
the
concept
of
``
walking
''
,
the
training
data
has
to
include
the
same
amount
of
pictures
of
walking
males
,
walking
females
,
walking
young
people
,
walking
old
people
,
walking
white
,
walking
black
,
walking
yellow
,
walking
tall
people
,
walking
short
people
,
walking
people
with
expensive
clothes
,
walking
people
with
cheap
clothes
,
etc.
.
if
the
training
data
lack
any
kind
of
data
,
then
the
``
walking
''
may
become
a
privilege
of
some
people
with
certain
tags
,
then
leading
to
racial
discrimination
,
gender
discrimination
,
wealth
discrimination
and
so
on
.
actually
,
the
bias
caused
by
disproportionately
training
data
is
very
common
.
according
to
the
disclosure
of
shreya
shankar
,
a
researcher
from
stanford
,
only
3
percent
of
pictures
in
imagenet
are
related
to
chinese
and
indianness
,
making
ai
has
a
much
worse
performance
when
recognizing
these
kinds
of
images
.
another
extreme
example
is
tay
,
which
was
a
chat
robot
ai
in
tweeters
.
since
most
of
the
users
provided
immoral
thoughts
to
her
,
tay
finally
became
a
completely
anti-social
bad
girl
.
moreover
,
a
number
of
algorithms
promote
these
kinds
of
statistics
since
they
try
to
eliminate
irrelevant
data
and
thus
give
``
crucial
''
factors
more
weights
.
these
algorithms
accept
the
biases
people
have
and
magnify
them
through
the
training
process
.
in
addition
,
most
ai
systems
will
not
explicitly
tell
computer
scientists
that
they
take
``
gender
''
as
an
important
factor
to
calculate
or
predict
results
.
instead
,
ai
systems
just
learn
themselves
and
only
present
the
final
results
.
unfortunately
,
it
is
very
likely
that
the
final
results
are
decent
the
most
of
the
time
because
biased
factors
might
indicate
some
trends
and
therefore
contribute
somewhat
to
the
right
results
-lrb-
but
it
is
definitely
improper
to
use
such
factors
which
individuals
can
not
change
or
determine
-rrb-
.
consequently
,
computer
scientists
may
be
satisfied
with
the
final
results
and
do
not
realize
the
bias
happens
.
also
,
even
if
computer
scientists
notice
that
there
are
some
bias
factors
in
their
ai
systems
,
they
are
not
able
to
get
rid
of
them
easily
.
take
image
recognition
as
an
example
:
the
ai
systems
will
give
each
pixel
different
weights
to
show
how
much
they
relate
to
the
final
prediction
.
therefore
,
a
biased
factor
may
refer
to
the
weights
of
millions
of
pixels
,
which
might
be
very
difficult
to
interfere
with
computer
engineers
.
to
interfere
with
training
data
is
also
difficult
because
it
means
to
abandon
a
great
many
data
or
it
means
a
great
many
complex
pretreatments
which
require
tremendous
``
extra
''
funding
.
thus
,
it
is
hard
to
demand
every
ai
company
to
spend
these
extra
works
.
based
on
the
discussion
above
,
the
idea
that
ai
can
eliminate
bias
for
us
is
not
that
authentic
.
oppositely
,
ai
may
promote
bias
or
discrimination
in
the
current
stage
.
