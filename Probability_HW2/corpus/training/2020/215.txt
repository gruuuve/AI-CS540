overlooked
concerns
artificial
intelligence
and
life
in
2030
produces
many
categorical
,
optimistic
claims
for
the
future
of
artificial
intelligence
-lrb-
ai
-rrb-
in
our
society
.
the
categories
defined
by
the
article
consist
of
``
transportation
;
service
robots
;
healthcare
;
education
,
low-resource
communities
;
public
safety
and
security
;
employment
and
workplace
;
and
entertainment
.
''
while
many
of
the
assertions
in
the
article
may
be
discussed
or
criticized
,
this
paper
finds
fault
with
the
implied
claim
that
ai
will
definitively
have
a
net
benefit
to
both
public
safety
and
security
.
almost
all
of
the
claims
made
by
the
authors
appear
to
be
well-cited
,
but
the
following
excerpt
can
be
used
to
highlight
one
particular
implied
assertion
:
``
as
with
most
issues
,
there
are
benefits
and
risks
...
while
there
are
legitimate
concerns
that
policing
that
incorporates
ai
may
become
overbearing
or
pervasive
in
some
contexts
,
the
opposite
is
also
possible
.
ai
may
enable
policing
to
become
more
targeted
and
used
only
when
needed
.
and
assuming
careful
deployment
,
ai
may
also
help
remove
some
of
the
bias
inherent
in
human
decision-making
.
''
while
it
is
likely
true
that
ai
will
reduce
human
bias
when
it
comes
to
policing
,
this
passage
downplays
the
negative
capabilities
of
the
technology
.
in
addition
to
that
,
the
article
sweeps
the
negative
consequences
under
the
rug
by
never
mentioning
those
concerns
again
.
it
is
self-evident
that
predictive
policing
subverts
both
the
notion
of
innocent
until
proven
guilty
and
warranted
search
,
and
that
the
potential
for
gubernatorial
abuse
is
ripe
in
such
a
system
.
an
ai
combing
through
chat
history
,
product
purchases
,
etc.
,
is
still
a
search
without
a
warrant
,
and
warrantless
search
presumes
guilt
without
probable
cause
.
one
example
of
abuse
close
to
home
was
the
fbi
's
usage
of
nsa
's
surveillance
data
to
monitor
thousands
of
american
citizens
.
according
to
the
verge
,
the
fbi
was
permitted
to
search
a
vast
``
database
of
electronic
intelligence
''
intended
for
national
security
.
proponents
of
ai
's
involvement
in
policework
might
argue
that
this
surveillance
was
necessary
to
advance
our
interests
in
security
and
safety
,
but
the
agents
utilized
the
tool
to
``
-lrb-
look
-rrb-
up
friends
,
family
,
and
coworkers
.
''
as
for
supplementary
examples
of
abuse
,
one
need
only
consider
china
's
dystopian
social
credit
system
and
mass
surveillance
programs
to
see
how
easily
ai
can
be
used
for
malevolence
.
according
to
the
new
york
times
,
china
uses
its
facial
recognition
software
to
target
muslim
minorities
,
``
ushering
in
a
new
era
of
automated
racism
.
''
now
,
it
may
be
entirely
plausible
that
advances
in
ai
will
be
for
the
greater
good
by
eliminating
bias
and
reducing
unnecessary
policing
of
communities
,
but
the
article
rarely
touches
the
adversity
that
may
be
derived
from
ai
.
to
hardly
mention
ai
's
abhorrent
capacity
is
to
imply
that
new
and
unforeseen
tools
will
likely
lead
us
down
a
positive
path
,
but
ai
is
only
as
good
as
the
hands
that
control
it
.
whether
for
better
or
worse
,
ai
is
going
to
steadily
infiltrate
our
lives
.
we
must
be
cognizant
of
the
dangerous
aspects
as
well
as
the
good
to
create
excellent
policy
regulating
ai
.
even
if
our
initial
reactions
are
knee-jerk
and
stymy
fast
development
,
it
's
better
than
sacrificing
our
liberties
and
safety
.
references
:
https://www.theverge.com/2019/10/8/20905678/fbi-violated-americans-privacy-rights-court-ruling-fisc-surveillance-nsa
https://www.nytimes.com/2019/04/14/technology/china-surveillance-artificial-intelligence-racial-profiling.html
