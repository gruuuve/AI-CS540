ai100
reflection
the
one
hundred
year
study
on
artificial
intelligence
-lrb-
ai
-rrb-
completed
in
2015
looks
at
what
ai
is
believed
to
look
like
in
the
year
2030
.
the
study
looks
to
define
ai
,
describe
its
current
state
within
major
domains
,
and
define
what
future
legislative
policy
needs
to
look
like
for
ai
to
be
implemented
effectively
and
safely
.
when
looking
at
some
of
the
claims
made
within
the
study
,
there
exist
some
flaws
.
specifically
,
the
ease
of
getting
the
public
to
trust
ai
and
reducing
bias
through
ai
.
one
of
the
major
hurdles
when
implementing
and
deploying
ai
technologies
through
various
domains
will
be
the
ability
to
get
the
public
to
trust
ai
technologies
.
as
claimed
in
the
paper
,
it
is
believed
that
by
2030
autonomous
vehicles
will
the
major
form
of
transportation
and
that
it
will
transform
that
way
that
humans
will
be
able
to
move
in
general
.
the
general
opinion
by
most
people
is
that
ai
is
unsafe
.
for
many
people
it
is
hard
to
understand
the
way
that
ai
works
and
makes
decisions
.
ai
algorithms
,
especially
those
implemented
within
autonomous
cars
will
be
able
to
make
decisions
more
accurately
and
safely
,
compared
to
the
average
driver
.
this
will
most
likely
be
overlooked
by
the
general
population
as
any
mistake
made
by
ai
will
be
scrutinized
much
more
compared
to
human
error
.
again
this
negative
sentiment
about
ai
is
amplified
by
the
idea
that
ai
will
replace
the
jobs
of
many
across
multiple
sectors
of
industry
.
even
legislative
policy
passed
to
help
those
who
have
or
will
lose
jobs
to
ai
technologies
will
not
be
enough
.
the
combination
of
this
negative
sentiment
about
ai
and
the
scrutiny
that
it
will
undergo
,
will
most
likely
slow
down
the
implementation
of
ai
in
all
industries
until
ai
is
more
widely
understood
.
another
point
presented
within
the
paper
mentions
that
ai
will
help
to
reduce
the
bias
that
exists
in
some
industries
or
that
ai
can
detect
and
remove
bias
.
ai
covers
a
lot
of
different
implementations
and
algorithms
,
but
many
of
these
implementations
are
data
trained
models
.
this
means
that
the
training
data
fed
to
the
models
will
have
been
collected
by
humans
,
which
typically
will
contain
some
type
of
bias
.
this
will
inherently
create
an
ai
model
that
contains
the
bias
within
the
data
.
this
brings
up
the
idea
that
the
data
could
possibly
be
adjusted
by
a
human
to
correct
for
the
bias
.
by
having
a
human
adjust
the
data
,
this
inherently
presents
a
new
bias
into
the
data
.
instead
of
a
human
correcting
a
data
set
,
an
ai
algorithm
could
possibly
look
at
a
set
of
data
and
determine
if
bias
exists
.
this
could
create
an
unbias
data
set
that
could
then
be
used
to
train
a
model
,
but
the
problem
is
that
a
human
must
determine
whether
the
algorithm
is
correctly
removing
any
existing
bias
.
again
this
inherently
adds
a
level
of
bias
to
the
data
set
.
this
required
collaboration
between
human
and
machine
will
create
a
difficult
problem
for
removing
bias
from
algorithms
.
both
the
ideas
,
that
ai
will
ease
into
the
publics
'
favor
and
that
it
will
be
easy
for
ai
to
remove
bias
within
current
implementations
are
far
fetched
.
the
current
sentiment
about
ai
and
the
scrutiny
that
it
will
endure
will
most
certainly
hinder
ai
from
being
accepted
from
the
public
.
the
almost
certain
interaction
between
human
and
machine
when
reducing
bias
,
will
also
make
for
a
challenging
task
as
humans
are
inherently
bias
.
