stanford
's
100
year
study
on
artificial
intelligence
describes
the
current
state
of
ai
technology
in
eight
separate
domains
and
makes
predictions
for
the
future
within
each
domain
.
one
domain
was
public
safety
and
security
,
where
predictions
were
made
towards
the
future
of
implementing
ai
in
policing
and
detecting
crime
through
video
surveillance
while
also
investigating
online
sources
for
future
security
risks
.
i
'm
challenging
the
idea
of
this
implementation
in
modern
society
as
it
disregards
ethical
points
from
history
.
the
first
point
it
disregards
is
the
idea
of
being
innocent
until
proven
guilty
.
implementing
surveillance
and
crime
detection
throughout
cities
and
towns
puts
everyone
under
the
risk
of
being
labeled
a
criminal
.
although
the
security
levels
increase
in
the
area
,
the
effect
on
human
's
dignity
and
freedom
is
reduced
to
unethical
levels
.
the
implementation
also
produces
a
``
big
brother
''
effect
,
as
described
in
george
orwell
's
1984
book
,
where
everyone
is
under
constant
surveillance
and
the
thoughts
of
resistance
against
the
law
results
in
fear
and
suppression
of
individualism
.
when
it
comes
to
white
collar
crimes
and
how
ai
could
assist
in
solving
related
problems
,
the
study
makes
many
good
points
.
however
,
similar
systems
implemented
on
some
sites
have
shown
great
failure
in
policing
online
crimes
.
one
prime
example
of
poor
implementation
is
youtube
's
contentid
software
.
the
software
takes
into
account
youtube
's
policies
for
content
creators
on
the
website
and
police
's
the
creator
's
by
attempting
to
detect
broken
policies
through
posted
videos
.
the
software
has
been
around
for
a
few
years
and
has
grown
worse
and
worse
,
accusing
content
creators
of
breaking
policies
that
they
did
n't
commit
,
causing
the
creator
's
video
to
be
demonetized
.
the
main
problems
is
the
creator
's
reliance
on
their
video
's
income
which
is
disregarded
through
content
id
.
a
redesign
of
the
software
taking
into
account
the
welfare
and
economic
state
of
the
content
creator
needs
to
be
done
if
this
problem
persists
.
another
online
issue
with
ai
software
came
with
the
company
bethesda
softworks
,
who
two
years
ago
released
the
video
game
fallout
76
-lrb-
which
was
a
massive
failure
of
a
aaa
game
-rrb-
.
in
order
to
detect
cheating
within
the
game
,
the
company
pushed
out
an
update
that
uses
ai
technology
to
determine
if
players
were
breaking
their
rules
.
after
a
month
,
the
situation
was
complete
chaos
where
innocent
players
were
being
banned
from
the
game
and
players
who
abused
the
glitches
and
bugs
in
the
game
were
also
banned
for
unjust
reasons
.
the
situation
spiraled
out
of
bethesda
's
control
,
creating
an
example
of
how
ai
security
online
can
go
horribly
wrong
and
is
not
foolproof
.
certain
points
made
about
safety
and
security
in
this
domain
should
be
focused
on
more
than
others
,
including
the
training
of
police
force
through
ai
technology
,
improving
airport
security
to
increase
safety
while
also
increasing
efficiency
,
and
also
investigating
social
media
for
future
attacks
and
risks
.
the
future
of
ai
in
public
safety
and
security
should
not
be
implemented
to
become
fully
automated
like
the
study
is
motioning
towards
,
but
rather
it
should
be
greatly
limited
to
assisting
human
control
to
increase
efficiency
and
security
in
appropriate
areas
like
airports
and
public
gathering
areas
.
