although
the
author
claims
that
ai
will
help
accelerate
work
automation
and
intelligence
,
while
providing
more
efficient
and
high-quality
medical
services
.
however
,
in
the
current
society
,
the
automation
of
work
may
bring
a
more
serious
wave
of
unemployment
than
great
depression
and
artificial
intelligence
may
not
be
of
much
help
to
improve
healthcare
analytics
in
the
short
term
.
first
,
although
artificial
intelligence
can
create
a
large
number
of
new
jobs
,
it
will
also
replace
more
old
jobs
.
due
to
the
characteristics
of
the
existing
ai
,
the
occupations
to
be
replaced
will
mainly
focus
on
tasks
that
require
high
accuracy
and
repeatability
,
such
as
food
production
and
manufacturing
.
to
make
matters
worse
,
according
to
the
brookings
institution
data
,
displaced
people
are
often
at
a
disadvantage
in
terms
of
employment
,
education
,
race
,
age
,
etc.
,
which
affects
job
competitiveness
.
this
means
that
the
displaced
will
face
severe
employment
pressure
once
they
lose
their
jobs
.
this
may
lead
to
large-scale
structural
unemployment
in
a
short
period
of
time
.
mark
muro
,
a
senior
researcher
at
the
brookings
institution
's
metropolitan
policy
program
,
said
that
those
who
struggle
on
the
food
and
clothing
line
are
most
likely
to
be
threatened
by
automation
.
the
worst
result
that
artificial
intelligence
can
bring
in
the
short
term
is
the
soaring
unemployment
rate
and
the
widening
gap
between
the
rich
and
the
poor
.
the
author
also
believes
that
artificial
intelligence
will
play
an
important
role
in
health
care
.
such
as
building
better
healthcare
robotics
and
providing
high-quality
mobile
health
services
.
but
ai
's
role
in
healthcare
analytics
may
not
be
as
good
as
the
authors
thought
.
because
at
this
stage
we
do
not
have
a
deep
understanding
of
some
ai
methods
.
this
results
in
software
that
uses
related
ai
algorithms
often
presenting
a
`
black
box
'
.
it
is
difficult
for
some
ai
methods
to
explain
the
behavior
of
ai
systems
.
this
can
lead
to
failure
or
even
misdiagnosis
.
for
example
,
ibm
watson
health
's
cancer
ai
algorithm
-lrb-
known
as
watson
for
oncology
-rrb-
is
a
recent
case
.
this
algorithm
has
been
shown
to
recommend
bevacizumab
to
patients
with
severe
bleeding
,
a
clear
contraindication
and
a
``
black
box
''
warning
of
the
drug
.
this
example
illustrates
that
a
flawed
ai
algorithm
can
cause
significant
harm
to
patients
and
lead
to
medical
accidents
.
another
major
aspect
is
the
issue
of
responsibility
.
who
should
be
responsible
for
medical
accidents
if
there
is
no
doctor
involved
in
the
diagnosis
of
the
disease
?
and
we
do
n't
even
know
why
the
system
is
going
wrong
?
who
is
responsible
when
doctors
accept
wrong
advice
from
ai
?
this
puts
the
ai
algorithm
in
medical
practice
in
a
dilemma
.
accepting
the
use
of
opaque
ai
algorithms
for
patient
care
will
significantly
reduce
development
costs
and
technology
iterations
,
but
face
the
risk
of
misdiagnosis
.
if
you
do
not
accept
the
use
of
opaque
ai
algorithms
for
patient
care
,
the
development
of
related
applications
and
algorithm
development
will
be
slow
.
the
privacy
of
medical
data
is
also
a
challenge
facing
researchers
.
many
systems
not
only
run
in
the
cloud
,
but
also
some
forms
of
useful
medical
data
are
inherently
identifiable
,
such
as
analyzing
facial
features
in
the
system
to
diagnose
diseases
.
when
it
comes
to
signs
,
we
are
not
likely
to
obscure
the
facial
features
of
patients
,
and
data
leakage
may
be
inevitable
.
