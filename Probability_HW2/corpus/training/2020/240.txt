the
one
hundred
year
study
on
artificial
intelligence
strongly
advocates
for
the
widespread
application
of
ai
technologies
.
while
research
in
the
area
of
ai
is
critical
,
it
is
important
to
put
privacy
and
personal
data
security
first
.
there
is
already
an
extensive
history
of
abuse
of
these
technologies
,
both
by
governments
and
by
corporations
.
users
'
data
needs
protection
and
these
systems
need
more
transparency
.
additionally
,
the
question
needs
to
be
asked
--
do
ai
technologies
in
every
aspect
of
life
yield
a
net
benefit
?
it
's
certainly
easy
to
argue
that
ai
applications
in
healthcare
that
help
doctors
make
diagnoses
are
a
good
thing
;
however
,
patients
should
have
some
control
over
their
data
.
no
system
should
be
spying
on
them
without
their
permission
.
the
report
objects
to
the
fda
's
slow
pace
in
approving
such
diagnostic
software
,
calling
it
a
``
barrier
to
innovation
.
''
but
hipaa
requirements
are
effective
at
shielding
patients
'
personal
information
from
self-interested
parties
who
may
misuse
that
data
.
on
the
flip
side
,
technologies
like
medical
robots
and
medical
image
analysis
can
easily
be
used
while
still
protecting
patient
data
,
and
offer
a
clear
benefit
to
patients
and
doctors
.
the
report
also
makes
the
case
for
ai
technologies
in
policing
and
security
applications
.
the
history
of
abuse
of
such
technologies
in
this
sector
is
overwhelming
and
should
n't
be
ignored
.
governments
,
for
the
past
few
decades
at
least
and
likely
even
longer
,
have
used
digital
technologies
to
spy
on
their
citizens
--
collecting
data
without
their
consent
.
in
2013
,
for
example
,
a
trove
of
us
government
programs
were
revealed
that
were
designed
to
collect
data
on
civilians
with
little
oversight
and
no
consent
in
the
name
of
national
security
.
while
it
's
important
to
be
able
to
protect
civilians
and
enforce
laws
,
many
aspects
of
this
work
may
be
better
left
in
the
hands
of
men
than
in
machines
.
again
,
though
,
certain
technologies
are
well
implemented
--
operating
transparently
with
the
consent
of
users
.
for
example
,
the
report
mentions
systems
to
detect
credit
card
fraud
.
such
systems
are
often
offered
by
credit
companies
and
are
opt-in
.
these
transparent
technologies
should
be
a
model
for
the
implementation
of
ai
and
data
gathering
in
the
field
of
security
and
public
safety
.
in
other
areas
,
it
becomes
much
more
difficult
to
decide
whether
ai
is
a
net
good
.
as
mentioned
in
the
report
,
these
technologies
clearly
increase
economic
productivity
,
but
they
also
may
increase
economic
inequality
.
while
ai
improves
quality
of
life
for
many
,
there
are
also
consequences
that
need
to
be
taken
into
consideration
.
individuals
'
data
needs
to
be
protected
and
informed
consent
is
paramount
.
developments
in
the
field
should
reflect
these
values
and
take
users
'
priorities
into
consideration
.
