one
of
the
main
points
the
stanford
ai
report
makes
in
its
focus
on
entertainment
is
that
ai
can
be
-lrb-
and
in
many
cases
,
is
-rrb-
used
to
process
,
moderate
,
and
share
digital
entertainment
content
.
specifically
,
the
article
mentions
that
ai
could
allow
entertainment
to
become
more
interactive
,
engaging
,
and
personalized
on
an
individual
basis
.
however
,
the
implementation
of
ai
in
entertainment
industries
will
undoubtedly
create
unforeseen
challenges
and
consequences
for
producers
and
consumers
alike
because
of
how
human
beings
subjectively
value
and
interpret
entertainment
content
.
as
the
report
mentions
,
crowdsourcing
might
help
ai
understand
human
intentions
and
desires
,
considering
that
subjective
problems
are
often
difficult
for
ai
to
solve
in
a
vacuum
.
however
,
the
overall
quality
of
entertainment
content
-lrb-
including
music
,
video
games
,
or
social
media
posts
-rrb-
is
largely
subjective
,
and
the
metrics
used
to
measure
,
interpret
,
and
categorize
content
can
vary
depending
on
human
morals
and
social
context
.
in
a
text
conversation
,
for
instance
,
it
may
be
difficult
for
ai
to
interpret
emotions
conveyed
through
text
-lrb-
such
as
happiness
,
anger
,
or
sarcasm
-rrb-
without
conversational
or
real
world
context
.
likewise
,
it
is
often
possible
to
use
the
same
phrases
or
words
earnestly
or
facetiously
.
ambiguous
phrases
such
as
``
you
're
awful
''
or
``
i
ca
n't
breathe
''
could
potentially
convey
disgust
or
humor
,
but
they
might
also
be
interpreted
literally
in
other
circumstances
.
considering
the
myriad
of
purposes
that
social
media
can
be
used
for
,
improperly
employing
ai
to
regulate
,
promote
,
or
ban
specific
content
or
ideas
could
therefore
create
unintentional
inconveniences
for
users
and
website
administrators
alike
.
many
modern
social
media
websites
have
already
implemented
ai
in
some
form
to
varying
degrees
of
success
.
the
video
sharing
website
youtube
,
for
example
,
employs
ai
for
many
purposes
.
these
purposes
range
from
removing
rule
breaking
content
to
generating
video
recommendations
tailored
specifically
to
individual
users
.
in
the
former
case
,
deep
learning
has
been
used
to
automatically
delete
content
that
is
visually
offensive
,
violent
,
or
sexual
without
the
need
of
human
moderation
,
reducing
the
amount
of
resources
needed
to
filter
content
manually
.
in
most
cases
,
deleted
videos
objectively
violate
youtube
's
established
guidelines
,
so
there
is
little
room
for
subjective
debate
.
in
the
latter
case
,
however
,
unintentional
consequences
of
tailored
content
include
the
formation
of
`
echo-chambers
'
-lrb-
which
promote
`
agreeable
'
content
and
omit
`
contrarian
'
content
-rrb-
and
the
potential
to
incentivize
creators
to
publish
formulaic
or
repetitive
content
.
algorithmic
omission
of
content
might
prevent
users
from
receiving
accurate
information
,
being
informed
about
current
issues
or
events
,
or
discovering
unique
or
otherwise
useful
content
.
on
the
other
hand
,
ai
that
promotes
specific
content
based
on
predetermined
metrics
might
unintentionally
discourage
innovation
among
content
creators
.
historical
youtube
content
trends
-lrb-
such
as
`
let
's
play
'
videos
,
`
top
10
'
lists
,
and
`
reaction
'
videos
-rrb-
demonstrate
that
ai
might
not
always
recommend
original
or
divergent
-lrb-
but
otherwise
rule
abiding
-rrb-
content
.
moreover
,
the
degree
to
which
individuals
value
specific
content
can
depend
on
real
world
context
and
trends
not
reflected
in
online
activity
.
consequently
,
ai
employed
to
tailor
content
may
only
be
able
to
accurately
predict
user
interests
to
a
limited
extent
.
