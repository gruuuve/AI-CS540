ai100
reflection
the
artificial
intelligence
and
life
in
2030
was
an
incredibly
interesting
read
.
i
learned
a
lot
about
the
direction
of
ai
in
a
variety
of
fields
,
and
am
excited
to
potentially
contribute
to
the
growth
of
the
field
in
the
coming
decades
.
though
i
viewed
many
of
the
findings
as
important
,
i
would
like
to
dispute
the
importance
of
one
topic
brought
up
repeatedly
in
the
article
:
big
data
.
on
page
eight
of
the
report
,
the
authors
state
that
machine
learning
has
been
propelled
forward
by
impressive
empirical
successes
of
artificial
neural
networks
,
``
trained
with
huge
sets
of
data
and
large-scale
computing
''
.
while
i
do
not
dispute
these
empirical
successes
,
as
i
'm
sure
there
have
been
many
,
i
believe
that
it
will
be
important
for
future
data
scientists
to
understand
the
dangers
that
incredibly
large
data
sets
can
pose
to
drawing
correlations
between
statistics
.
to
start
,
it
will
be
incredibly
important
to
ensure
that
the
data
sets
being
collected
and
used
to
train
ai
software
are
both
complete
and
free
from
inaccurate
data
points
.
cleaning
data
properly
is
not
the
only
challenge
that
computer
and
data
scientists
will
face
when
using
big
data
to
train
ai
in
the
near
future
.
as
author
and
statistician
nassim
nicholas
taleb
has
pointed
out
,
as
the
amount
of
variables
in
a
data
set
rises
,
the
amount
of
correlations
that
occur
as
``
significant
''
rises
in
a
non-linear
-lrb-
convex
-rrb-
manner
-lrb-
taleb
2013
-rrb-
.
this
essentially
means
that
the
amount
of
spurious
correlations
that
occur
rises
greatly
as
more
variables
are
taken
into
account
.
as
big
data
becomes
more
and
more
important
,
it
will
be
important
for
us
to
remember
that
not
all
variables
that
are
statistically
correlated
are
necessarily
linked
by
anything
more
than
chance
.
some
correlation
is
just
``
noise
''
,
and
it
is
a
new
problem
that
we
face
with
the
ability
to
collect
and
use
such
a
large
amount
of
data
.
additionally
,
the
collection
of
big
data
and
the
usage
of
it
in
training
artificial
intelligence
can
easily
be
exposed
to
potential
bias
.
as
displayed
in
this
report
,
everyone
will
be
impacted
by
the
constantly
increasing
usage
of
artificial
intelligence
on
a
day-to-day
basis
.
due
to
the
fact
that
ai
will
soon
become
so
universal
,
and
that
data
is
collected
to
train
the
ai
,
it
will
be
very
important
to
make
sure
that
the
populations
that
data
is
collected
from
are
as
diverse
as
possible
.
problems
associated
with
``
biased
algorithms
''
have
arisen
recently
in
the
general
field
of
software
development
.
as
those
problems
are
dealt
with
by
increasing
the
diversity
of
the
teams
developing
those
algorithms
,
steps
should
be
made
to
ensure
that
the
data
used
to
train
artificial
intelligence
is
of
the
best
possible
quality
in
terms
of
diversity
and
veracity
-
not
the
cheapest
.
while
i
do
believe
that
big
data
should
have
a
large
and
positive
impact
on
the
field
of
artificial
intelligence
,
we
must
remember
its
potential
flaws
.
if
data
is
cleaned
properly
,
collected
from
a
diverse
population
,
and
potential
spurious
correlations
are
replicated
by
multiple
studies
,
i
do
not
see
a
problem
with
the
widespread
usage
of
big
data
to
propel
ai
in
a
positive
directions
.
the
potential
for
big
data
and
its
usage
with
ai
is
vast
;
however
,
the
power
of
its
outcomes
should
not
be
underestimated
.
source
:
