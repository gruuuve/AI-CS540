there
have
been
giant
leaps
in
the
area
of
self-driving
vehicles
and
the
concept
of
smarter
cars
,
according
to
the
paper
by
stanford
,
ai
has
already
been
implemented
in
these
areas
and
has
delivered
good
results
and
will
continue
to
do
so
in
the
future
.
i
however
challenge
this
statement
as
i
believe
that
in
the
future
self-driving
cars
will
become
a
bane
to
the
human
society
.
self-driving
cars
will
lead
to
a
lack
in
jobs
as
drivers
of
different
automobiles
will
get
replaced
by
ai
powered
software
,
this
can
already
be
seen
in
the
cases
of
apps
like
uber
and
lyft
which
has
caused
a
decline
in
the
number
of
jobs
for
taxi
drivers
who
might
be
completely
overtaken
by
ai
in
the
future
.
on
the
other
hand
,
bus
drivers
and
truck
drivers
although
do
n't
have
to
compete
with
apps
like
uber
,
they
still
face
the
uncertainty
of
ai
taking
over
their
jobs
in
the
future
.
with
the
advent
of
self-driven
cars
,
driving
and
car
ownership
which
is
considered
to
be
something
special
is
now
losing
its
special
status
with
the
younger
generation
,
instead
of
being
a
hearty
investment
,
it
is
becoming
just
another
way
to
travel
,
driving
was
considered
synonymous
to
freedom
but
now
with
self-driving
cars
,
it
feels
more
like
robotic
slaves
that
are
there
to
do
our
bidding
.
with
self-driving
cars
,
accidents
are
bound
to
happen
,
as
no
technology
is
free
of
errors
,
fatalities
are
a
near
guarantee
.
the
moral
dilemma
that
will
be
faced
by
ai
algorithms
just
before
such
accidents
will
be
of
great
magnitude
,
if
an
accident
is
bound
to
happen
and
,
in
this
accident
,
if
the
ai
is
forced
to
either
choose
the
life
of
the
person
inside
the
vehicle
or
the
life
of
a
pedestrian
walking
nearby
,
what
will
it
choose
.
it
is
impossible
to
place
value
on
human
life
;
a
common
argument
is
that
it
should
choose
the
life
of
the
passenger
as
the
passenger
was
promised
safe
passage
,
but
then
what
of
the
life
of
the
poor
pedestrian
?
while
others
would
say
that
the
accident
is
something
unforeseen
and
the
passenger
should
be
the
one
to
lose
their
life
since
ai
can
not
be
given
the
right
to
take
the
life
of
another
willfully
.
now
if
a
third
or
a
fourth
factor
is
introduced
into
this
equation
,
will
the
ai
be
able
to
take
the
decisive
step
in
time
and
if
so
,
would
that
step
be
morally
right
.
the
choice
of
living
and
dying
is
one
that
should
be
the
right
of
the
ones
who
are
living
and
are
affected
by
these
decisions
,
a
human
being
will
almost
always
choose
their
own
life
over
the
life
of
strangers
and
they
pay
for
this
in
a
court
of
law
,
putting
ai
into
this
equation
breaks
the
cycle
of
action
and
consequence
.
