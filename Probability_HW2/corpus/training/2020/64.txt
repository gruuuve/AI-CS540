ai100
report
critique
the
one
hundred
year
study
on
artificial
intelligence
's
inaugural
report
aimed
to
provide
a
reasonable
starting
point
for
the
study
's
planned
long-term
survey
.
with
this
goal
in
mind
the
authors
cast
as
wide
a
net
as
they
could
,
setting
a
loose
working
definition
of
ai
to
capture
developing
technologies
in
diverse
fields
.
in
analyzing
the
present
state
of
ai
they
also
chose
a
bottom-up
organizational
approach
,
examining
broad
domains
that
might
be
impacted
by
many
different
technologies
rather
than
examining
how
specific
technologies
might
reach
out
into
various
domains
.
the
primary
strength
of
this
approach
is
the
setting
of
a
robust
precedent
,
helping
future
iterations
of
the
study
encompass
developments
that
are
yet
unknown
;
should
a
new
technology
emerge
,
its
effects
could
be
effectively
broken
down
by
domain
,
for
instance
.
the
report
's
weaknesses
include
a
failure
to
fully
exhaust
the
implications
of
specific
technologies
and
how
public
policy
might
address
them
,
but
most
importantly
,
to
effectively
prescribe
ai-related
policy
.
as
an
example
,
in
public
safety
and
security
on
page
36
,
the
authors
discuss
a
number
of
applications
of
ai
in
the
law
enforcement
and
security
.
in
the
section
,
they
mention
techniques
like
predictive
policing
,
event
classification
in
video
footage
,
analysis
of
behavior
-lrb-
speech
,
gait
-rrb-
,
and
crowd
control
simulations
.
this
approach
gives
a
good
overview
of
how
developing
technologies
can
be
applied
in
the
given
domain
but
does
little
to
explain
the
underlying
technology
;
computer
vision
in
particular
is
suggested
to
provide
many
of
these
predicted
applications
but
no
discussion
is
given
to
the
nature
of
computer
vision
,
its
fallibility
and
flaws
.
in
general
the
report
does
not
give
the
reader
a
strong
understanding
of
what
ai
technologies
can
actually
do
,
their
reliability
,
their
drawbacks
,
instead
using
vague
statements
like
``
humans
and
ai
systems
have
complementary
abilities
''
(42)
.
the
report
emphasizes
the
importance
of
public
trust
and
public
exposure
to
reliable
ai
technologies
to
build
that
trust
.
the
authors
repeat
this
idea
as
a
mantra
through
the
report
,
such
as
on
page
42
where
they
pin
the
responsibility
of
managing
public
views
of
ai
on
developers
:
``
design
strategies
that
enhance
the
ability
of
humans
to
understand
ai
systems
and
decisions
...
developers
should
help
manage
people
's
expectations
.
''
the
question
of
how
the
public
presently
perceives
ai
is
not
explored
,
nor
is
the
question
of
how
such
perception
is
in
fact
affected
by
changes
in
technology
.
it
seems
plausible
,
for
instance
,
that
modern
children
may
be
more
trusting
of
ai
systems
after
being
exposed
to
increasingly
smart
technology
during
formative
years
.
in
terms
of
prescriptions
for
public
policy
,
the
authors
set
conservative
goals
:
increase
ai
expertise
in
government
,
remove
impediments
to
research
on
ai
,
and
increase
funding
for
studies
of
ai
impact
(43)
.
it
is
true
that
ai
technologies
are
in
their
infancy
and
the
best
way
for
the
government
to
respond
is
to
increase
overall
preparedness
for
the
big
moving
and
shaking
they
will
be
doing
in
the
decades
to
come
.
however
,
the
authors
could
have
done
more
in
this
section
.
one
suggestion
might
be
to
emphasize
public
understanding
of
ai
technologies
-lrb-
by
introducing
school
curriculum
,
for
example
-rrb-
.
the
government
should
play
a
role
in
managing
public
expectations
and
readiness
for
ai
and
its
shortcomings
.
it
's
also
important
to
bolster
protections
against
abuses
of
ai
.
already
individuals
and
organizations
are
applying
ai
in
potentially
harmful
ways
.
it
is
not
too
soon
for
the
government
to
act
to
regulate
specific
technologies
but
also
broad
applications
of
ai
,
for
real
or
cyber
-
terrorism
,
for
media
manipulation\/fake
news
,
or
for
infringements
of
privacy
and
other
civil
rights
.
